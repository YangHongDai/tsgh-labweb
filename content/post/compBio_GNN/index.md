---
title: 計算生物學聊聊：圖神經網路與分子圖形
date: 2024-12-22
authors: ["戴揚紘", ""]
commentable: true
categories: [計算生物學]
tags: [Computational biology, Graph nueral network]
isCJKLanguage: true
draft: true
---
<!--more-->
## Quick look
分子表示法（molecular representation）在計算化學中扮演重要的角色，它使化學家和數據科學家能夠將複雜的化學結構轉換成機器可理解的形式，用於數據存儲和計算分析。這些表示法在格式、易用性和應用場景上存在顯著的差異，每種表示法在特定類型的分析中具有其獨特的優勢和局限性，透過建構圖神經網路（Graph neural network）來預測分子的特性，這些表示法的差異會更為顯著。

本篇筆記出自於美國麻省理工學院的計算生物學課程MLCB24。課程影片請看[這裡](https://www.youtube.com/watch?v=6gkIjo4Jb4E&t=220s)。

## 常見的分子表示法
1. `SMILES (簡化分子輸入線性表示系統)`
2. `SMARTS（SMILES 任意目標規範）`
3. `InChI（國際化學標識符）`
4. `Molecular graph (分子圖)`

接下來會根據每一種表示法做介紹：

---
## SMILES
SMILES（Simplified Molecular Input Line Entry System）是一種基於`字串`的分子表示法，最初由美國環保署（EPA）開發，用於以緊密相連的線性格式捕捉分子的結構。目前為化學資訊學中最廣泛使用的小分子表示法之一。

#### 格式
例如，乙醇的 SMILES 表示為 `CCO`（省略氫原子）。`字母`和`數字`表示原子與鍵類型（單鍵、雙鍵等），`括號`則用來標示`分支`結構。

#### 優點
SMILES 具有高度壓縮性（compact），容易被大多數化學資訊軟體讀取，適合用於資料庫存儲。

#### 限制
`合成混淆`：SMILES 字串靈活性高，容易生成，但這種靈活性導致許多語法有效的 SMILES 字串可能無法解碼成實際分子。
`立體化學`：雖然 SMILES 可以包含立體化學資訊，但通常在實務上會被省略，當分子功能取決於立體資訊時，會導致問題產生。

---
## SMARTS（SMILES 任意目標規範）
`SMARTS` 是根據 SMILES 來擴展的表示法，允許在 SMILES 字串中進行`模式匹配`來識別特定的分子子結構。

#### 應用
SMARTS 對於化學資訊學中的`子結構搜索`特別有用，例如識別`芳香環`或其他分子`功能基團`。

#### 格式
例如，芳香環可以用`c1cccccc1`來表示。

#### 限制
儘管 SMARTS 在子結構搜索中功能強大，但比 SMILES 更`複雜`，需要對`化學模式`有更深入的理解才能有效使用。

---
## SELFIES（自引用嵌入字串）
`SELFIES` 是一種較新的表示法，主要在克服 SMILES 的一些限制。它更像是一種`分子編程語言`，允許完整解構字串，`系統化生成分子`，

#### 關鍵優勢
可以很好的耐受錯誤，所有的SELFIES字串都可以解構成某特定分子，不會導致訊息的喪失，有利於機器學習。

#### 格式
例如，苯環可以表示成：`C1=CC=CC=C1`。

#### 限制
SELFIES 雖然創新，但`較難閱讀`，且需進一步改進以確保化學空間中的採樣沒有偏誤。

---
## InChI（國際化學標識符）
`InChI` 是一種IUPAC開發的標準化分子表示法，保證每個分子與其 InChI 字串一一對應。包含多層的分子特徵，如連結性、價電子、空間化學與異構物等。

#### 應用
InChI 在`資料庫搜索`和`比較`中特別有價值，因為它允許直接進行`分子比較`，避免了因不同 SMILES 表示法導致的`多餘訊息`。因為SMILE並沒有賦予分子獨特性，因此需要電腦解讀，增加計算負擔。

#### 關鍵優勢
標準化的表示法，每一個表示法都對應到單一獨特的分子式。

#### 格式
例如，乙醇可以表示成：`1S/C2H6)/c1-2-3/h3H,2H2,1H3`。

#### 限制
InChI 的`複雜性`使其難以閱讀和解釋。由於簡潔性，許多人`更偏好用 SMILES 進行可視化`。目前有方法將SMILES表達法InChI化，藉此增加InChI的可讀性。

---
## 分子圖
`分子圖`是一種基於`圖形`的分子表示法，其中原子是頂點，鍵是邊。這種表示法捕捉了分子的所有信息，包括原子類型、鍵類型，甚至是立體化學。

#### 優點
分子圖全面地提供分子結構的完整描述，較為`直覺`，尤其適用於基於圖的機器學習中的計算分析。

#### 限制
與基於字串的格式不同，分子圖不如 SMILES 那麼`緊密`，也不適合快速搜索資料庫。分子圖更適合用於計算應用和視覺化，而非數據儲存。

---
## 分子表示法比較
圖一顯示不同分子表示法的總結。
![fig1](fig1.png '圖一 分子表示法比較')

---
## SMILES 表示法
#### 原子與鍵
- `一般原子`：在 SMILES 字串中，每個原子由其化學符號表示。大多數原子使用單個`大寫字母`表示（例如，C 表示碳，O 表示氧）。一些原子需要兩個字母的組合（如 `Na 表示鈉，Cl 表示氯`）。
- `芳香原子`：在 SMILES 中，`小寫字母`表示芳香化合物中的原子。例如，小寫的 c 表示`芳香碳`，常見於`苯環`中。
- `鍵`：`單鍵`通常為簡化`省略`，但也可使用單個破折號 `-` 明確表示。`雙鍵`用等號 `=` 表示，`三鍵`用井號 `#` 表示。芳香鍵通常省略，因為小寫原子符號已隱含芳香性。分子組件的分離：句點 `.` 用於表示分子中`不連接`的部分，例如鹽或離子對。例：`Na.Cl 表示氯化鈉`。


#### 鏈與分支
- `線性鏈`：簡單的原子鏈以`直線順序`表示。例如，乙醇的 SMILES 表示為 CCO，表示碳-碳-氧鏈。
- `分支`：SMILES 使用`括號`表示從主鏈分支的結構。主鏈從括號前的原子開始繼續。例如，`異丙醇 (2-propanol or isopropanol)`的 SMILES 表示為 `CC(O)C`，其中 `(O)` 表示`OH-`分支。

> 其他例子：
> 
> CC(=O)C: 2-Propanone
> 
> CC(CC)C: 2_Methylbutane
> 
> CC(C)CC(=O): 2-Methylbutanal
> 
> c1c(N)(=O)=O)cccc1: Nitrobenzene
> 
> CC(C)(C)CC: 2,2-Dimethylbutane


#### 環與環狀結構
- `環閉合`：SMILES 使用`數字`標記環閉合。例如，`苯`的表示為 `c1ccccc1`，其中 `1` 表示`第一和最後`的碳原子相連以完成環。相同的數字表示開環與閉環的原子位置。鍵的類型著記在原子之後，但在數字之前。
- `多重環`：對於更複雜的環系統，使用額外的數字來表示分子內的每個環。例如，`萘`的 SMILES 表示為 c1ccc2ccccc2c1，其中 1 和 2 標記了兩個融合的環 (圖二)。

![fig2](fig2.png '圖二 萘 (Naphthalene)的SMILES表示法')

#### 電荷
電荷表示：SMILES 使用卷曲括號 `{}` 和加號 `+` 或減號 `-` 表示原子的電荷。

#### 模稜兩可的名稱
若是比較容易讓人誤解的標示方法，用大括號 `[]` 來區分，如Sc沒有框起來的話表示Sulfur與aromatic carbon，而[Sc]則表示Scandium。

---
## Morgan 指紋：機器學習中的分子結構編碼
Morgan 指紋（也稱為`環狀指紋`）是一種強大的工具，可將分子結構轉換為`固定長度的二進制向量`，使其非常適合於機器學習應用。與需要詳細結構數據的完整分子圖不同，Morgan 指紋提供了一種`計算效率更高`的表示方式，捕捉每個原子周圍的結構特徵並以易於輸入機器學習模型的格式儲存。

#### Morgan 指紋的目的
- `定量結構-活性關係（QSAR）建模`：例如，預測分子的疏水性、溶解度或潛在生物活性。
- `高通量篩選`：在藥物發現中，用於快速篩選分子。

#### 主要優勢
- `固定長度表示`：每個分子無論大小都表示為特定長度的向量，與許多機器學習模型直接兼容。
- `結構資訊封裝`：通過編碼以原子為中心的子結構（達到`指定半徑`），捕捉`局部化學環境`。
- `計算效率`：這種表示方式`比生成完整分子圖更快`，並且生成的指紋可快速用於機器學習。

#### Morgan 如何運作？
生成 Morgan 指紋涉及一系列步驟，這些步驟專注於分子中的每個原子，並檢查其在指定半徑內的`局部結構` (圖三)。

- `以原子為中心的編碼`： 每個`原子`作為`中心點`，檢查其周圍的子結構。這些子結構的細節取決於設定的`半徑`。

> 定義半徑：
> 
> 半徑 0：僅編碼原子本身。
> 
> 半徑 1：編碼原子及其鄰近原子。
> 
> 半徑 2：編碼原子、其鄰近原子及這些鄰近原子的鄰居。
> 
> 通常，使用半徑 2 即可捕捉足夠的細節，而不會導致向量過於龐大。

- `將子結構映射到比特 (bit) 位置`：每個環狀子結構都被編碼為一個`二進制向量（bit string）`，其中特定特徵（例如原子、鍵、環）的存在記錄為`1`，缺失記錄為`0`。半徑決定了圍繞中心原子的原子層數（例如，半徑為2時包括距離中心原子兩鍵以內的原子和鍵）。

- `子結構碰撞`：子結構被哈希(hash)轉換為固定長度的指紋（例如1024位），這可能導致哈希碰撞，即多個子結構可能映射到相同的位。可以考慮增加長度來解決。

![fig3](fig3.png '[圖三 Morgan fingerprint](https://towardsdatascience.com/a-practical-introduction-to-the-use-of-molecular-fingerprints-in-drug-discovery-7f15021be2b1)')

#### Morgan 指紋生成範例
1. 第一步：從分子內的某原子開始。
2. 第二步：根據特定的半徑來建構子結構。
3. 第三步：使用Hash table來將子結構轉換成獨特的比特編號。
4. 第四步：針對每一個原子完成以上步驟，產生一個二元分子指紋，表示整個分子。

#### 以乙醇（CCO）為例
每個碳和氧原子作為中心點，評估其半徑 2 內的子結構。

這將產生以下信息：
1. 原子 1：第一個碳及其鄰居（第二個碳和氧）。
2. 原子 2：第二個碳及其鄰居（第一個碳和氧）。
3. 原子 3：氧及其鄰近的碳。
每個原子和子結構會映射到指紋中，形成唯一表示乙醇結構的比特向量。

#### Morgan 指紋的優點
1. 對結構改變非常敏感，結構的些微修飾都可以被捕捉。
2. 效率高。
3. 廣泛使用於常見化學資訊學的工具中，如`RDKit`，也常用在視覺篩選與相似性搜索中。

#### 半徑與比特向量長度的平衡
半徑增加的影響：
1. 半徑越大，捕捉的子結構越詳細，但需要更大的向量以避免碰撞。
2. 半徑 2 提供了適度的細節，廣泛用於化學資訊學。
3. 半徑 3 或更大通常僅在需要非常細粒度結構細節時使用，但會顯著增加計算需求和複雜性。

#### 向量長度
常用長度為 1024 或 2048 比特。更大的向量幫助減少哈希碰撞，但在數據集較小時可能導致稀疏性問題。

#### 在機器學習中的解釋與應用
Morgan 指紋將複雜的分子結構轉換為向量空間表示，其中具有相似拓撲特徵的分子具有相似的指紋。結果向量可用於以下機器學習模型：
1. `隨機森林`：適合特徵豐富的數據集，向量直接表示分子特徵。
2. `多層感知機（MLP）`：能有效處理 Morgan 指紋，學習數據中的非線性模式。
3. 其他演算法：包括支持向量機（SVM）和邏輯回歸在內的任何處理二進制或數值向量的演算法均可使用 Morgan 指紋。

#### 限制與考量
1. `不可逆`：指紋無法反向解碼為原始分子。
2. 碰撞問題：不同的分子結構可能映射到相同的比特位置，尤其是在`較小的比特向量`或`大分子`時。
3. 不適用於大生物分子：對於`非常大的生物分子（如蛋白質）`，Morgan 指紋可能不適用，因為結構的複雜性超出了其表達能力。

---
## 分子圖：化學結構的進階表示
分子圖是一種靈活且精細的方式，能夠以數學形式表示分子，特別是在指紋`無法捕捉足夠結構細節`時尤其有用。與比特向量指紋不同，分子圖提供了分子結構的`直接映射`，將每個原子作為`節點 (node)`，每條鍵作為`邊 (edge)`。這種基於結構的表示允許更高的`特異性`和數據的豐富性，使其成為`圖神經網絡（Graph Neural Networks, GNNs）`的最佳輸入，尤其適用於需要深入探索原子間的關係時，例如定量QSAR和藥物設計。

#### 分子圖的結構
1. `節點與邊`：在分子圖中，每個`節點表示一個原子`，每條`邊表示一條化學鍵`。這種結構捕捉了分子內的原子類型及鍵類型（單鍵、雙鍵、三鍵或芳香鍵），能夠詳細描述化學關係。
2. `節點標籤`：每個節點可以攜帶標籤或類型（例如，碳用 C 表示，氮用 N 表示），以區分不同的原子類型。
3. `邊標籤`：邊可以標示鍵的類型（如單鍵、雙鍵、三鍵等）。這在分子圖中尤為重要，因為鍵類型對分子的化學行為和特性有著重要影響。

#### 圖的種類
1. `方向性`：在大多數情況下，分子圖是`無向 (undirected)`的，因為`化學鍵通常沒有方向性`。但在某些情境下，如`化學反應`網絡中，可以使用`有向圖 (directed)`來表示從反應物到產物的轉化流程。
2. `圖標籤`：原子和鍵都被標示，說明原子和鍵的類型，在對於需要化學分子細節的探討中很重要。
3. `加權圖`：雖然在基本分子圖中不常使用，但可以引入`加權邊`以指示`鍵強度`、相互作用強度或其他結構行為的`先驗知識`。

#### 分子圖的表示方法
#### 鄰接矩陣：
鄰接矩陣提供了一種表格式的圖表示，其中每個單元格表示原子之間是否存在鍵（或鍵的類型）。例如，若原子 

(i,j) 的值為 1（或表示鍵類型的整數）；否則為 0。
#### 對稱性：對於無向圖，鄰接矩陣是對稱的；對於有向圖，則是非對稱的，反映每條邊的方向性。
鄰接清單：
在處理大型圖（如社交網絡或大規模數據集）時，鄰接清單比矩陣更高效。每個原子只保存與其直接相連的原子清單，大大減少稀疏網絡中的存儲需求。
#### 稀疏矩陣表示：
另一種選擇是使用稀疏矩陣，只存儲非零值（即存在鍵的原子對），進一步降低內存使用量。
#### 圖的可視化：
分子圖也可以被可視化，提供直觀的方式來檢查分子結構、理解其複雜性並排查表示中的問題。
分子圖的應用與優勢

#### 完整的結構編碼：分子圖保留了分子的完整拓撲結構，允許對其特性和相互作用進行更深入的檢查。
與圖神經網絡（GNNs）的兼容性：分子圖可以與 GNNs 無縫集成，後者專門設計用於處理圖結構數據。
增強的預測建模：基於分子圖構建的 GNN 模型能夠更準確地預測分子的各種特性，如生物活性、毒性、溶解度和結合親和力。
圖神經網絡（GNNs）在分子建模中的應用

消息傳遞：在 GNN 中，每個節點通過一種稱為消息傳遞的迭代過程與其鄰居進行通信。這允許每個節點聚合鄰近節點的信息，有效地捕捉其分子環境的影響。
分層結構：與傳統神經網絡類似，GNN 有多層結構，每層允許圖捕捉分子中越來越遠的關係。
可定制性：GNN 可以納入方向性和邊權重的設計，特別適合於處理具有專門相互作用的分子結構。
不限於分子環境的圖應用

雖然分子圖是化學中的自然選擇，但其原則和技術可廣泛應用於其他與圖相關的領域，例如：

社交網絡：節點表示個體，邊表示聯繫（通常是有向的）。
通訊網絡：路由信息，其中節點表示服務器或路由器，邊表示數據流路徑。
生物網絡：基因與蛋白質的交互網絡，節點表示基因或蛋白質，邊表示相互作用或調控關係。
小結
分子圖提供了分子結構的全面表示，捕捉了指紋可能忽略的細微差異。這種詳細的表示使得 GNN 能夠深入分析分子，為特性預測和藥物發現開啟了新的可能性。通過有效利用分子圖，研究人員可以從化學數據中提取更豐富的見解，推進理論理解與實際應用。










接下來，我將翻譯「分子圖在藥物發現中的應用」內容，請稍候。

分子圖在藥物發現中的應用
分子圖在藥物發現和開發的各個階段都不可或缺，能夠精準捕捉並操作分子的完整結構。以下是分子圖如何顯著提升藥物開發流程的幾種方式：

1. 化學相似性搜索

當一種領先化合物顯示出與特定靶點的良好結合親和力時，研究人員通常會尋找與之結構相似的化合物，因為它們可能具有類似的活性。通過分子圖，我們可以編碼已知化合物的結構特徵，並在包含數百萬化合物的大型化學庫中搜索類似結構。

優勢：研究人員可以優先選擇較小且更具針對性的分子集進行初步測試，從而減少大規模篩選的成本和資源使用。
特別用途：此方法在資源有限或同時進行多個藥物發現項目時尤為重要。
2. 定量結構-活性關係（QSAR）建模

QSAR 模型使用分子圖來預測各種生物化學和藥代動力學特性。例如，可以基於分子結構預測以下屬性：

溶解度
血腦屏障的滲透性
ADME（吸收、分布、代謝、排泄）
毒性
分子圖為 QSAR 模型提供了基於分子特徵與目標特性相關性的基礎，從而幫助研究人員在實驗測試之前篩選化合物。

3. 圖神經網絡（GNNs）

分子圖是圖神經網絡（Graph Neural Networks, GNNs）的主要數據格式。GNNs 特別適合於學習圖結構數據中的複雜關係。

應用於分子圖：GNNs 可預測特定的分子屬性、結合親和力，甚至通過建模分子層級的交互，識別潛在副作用或不良反應。
優勢：GNNs 已成為現代計算藥物發現中的關鍵工具，能夠處理分子結構的複雜性。
4. 基於結構的藥物設計

分子圖允許進行基於結構的藥物設計，通過表徵完整的分子結構，支持更準確的模擬與分子-靶標交互的預測。

應用：研究人員可以利用基於分子圖的表示法來模擬結合能量及交互動態，設計專門優化與靶標結合的化合物。
卷積神經網絡（CNNs）作為 GNNs 的基礎
為更直觀地理解圖神經網絡（GNNs），可以先考慮卷積神經網絡（CNNs）的結構與功能，因為 CNNs 廣泛應用於影像處理。

1. CNN 處理 2D 網格數據

像素為單位：CNN 將每個像素視為一個單位，並與相鄰像素進行連接（垂直或水平），從而學習局部模式（如邊緣、梯度和紋理）。
層級學習：隨著網絡層數的增加，CNN 將這些低級特徵聚合為更高級模式，最終能夠識別複雜對象（例如貓、狗或汽車）。
2. 從 CNN 到幾何深度學習（GDL）的過渡

幾何深度學習的目標：將 CNN 在結構化數據（如影像）上的成功推廣到非結構化、非歐幾里得數據，如圖和流形。
圖結構的特性：圖與網格或矩陣不同，因其缺乏固定的節點排列且連接多樣化，因此需要專門的神經網絡架構。
3. 圖神經網絡（GNNs）如何擴展 CNN 的原則

消息傳遞或鄰居聚合：在 GNN 中，圖中的每個節點（如分子中的原子）從其鄰居（直接相連的節點）中收集信息，並反覆進行該過程，學習局部與全局模式。
層級特徵學習：GNNs 通過多層聚合，逐步捕捉分子結構的相互作用，類似 CNN 中逐層學習更複雜特徵。
GNNs 的可擴展性與應用

處理方向性與加權邊：GNNs 可處理有向和無向圖，特別是在處理具有特殊交互的分子結構時。
標籤與權重的靈活性：GNNs 支持節點與邊標籤，以及不同鍵類型或交互強度的加權邊，使其能處理多樣化的圖結構。
小結
分子圖在藥物發現與開發中是至關重要的工具，為深入分析和預測提供了堅實的基礎。通過結合圖神經網絡和幾何深度學習的概念，我們可以分析分子的複雜關係結構，捕捉有效藥物設計所需的細微差異，推動分子與化學資訊學機器學習應用的邊界。

接下來，我將翻譯「幾何深度學習：擴展深度學習到複雜結構」部分內容，請稍候。

幾何深度學習：擴展深度學習到複雜結構
幾何深度學習（Geometric Deep Learning, GDL）是一種將傳統深度學習方法推廣到更廣泛數據結構的技術，包括圖、點雲和流形等非歐幾里得數據結構。這種方法特別適合處理依賴關係和連接關係至關重要的任務，例如分子建模和物理模擬。

幾何深度學習中的複雜結構

在許多應用中，數據並非自然適合於簡單的網格或序列。常見情境包括：

圖：在社交網絡、分子結構和知識圖譜中，節點表示實體，邊表示關係或交互。
3D 點雲：出現在計算機視覺任務中（如 3D 對象識別）或分子與結構生物學中，其中點表示空間中的原子或分子。
流形：常出現在高維空間中，數據分佈於低維但連續平滑的曲面上。
在這些情境下，空間關係往往比固定結構的排列更重要，連接性本身包含了有價值的信息。

對稱性、不變性與等變性

幾何深度學習的一個核心方面是處理對稱性和特性如不變性和等變性，確保模型在數據變換時的輸出具有可預測性。

不變性： 模型對某種變換不敏感，即無論輸入經歷怎樣的變換，輸出保持不變。
例：一個模型在預測分子溶解度時應該對分子的旋轉或平移保持不變，因為這些變換不影響分子的溶解性。
等變性： 模型的輸出會隨輸入的變換而相應變化。例如，分子動力學模擬中，對參考框架的旋轉應該導致原子位置與動量的相應旋轉。
在模型中實現不變性與等變性

設計不變或等變層： 神經網絡層的設計可以天然處理變換。例如，在圖神經網絡（GNN）中，層的設計可以基於節點的連接方式而非空間排列進行信息聚合，從而實現這些性質。
基於懲罰的正則化： 在目標函數中加入懲罰項，如果模型的輸出在變換下不符合預期則增加損失。這種方式驅動模型學習所需的不變性或等變性。
數據增強： 通過對訓練數據進行多種變換（如旋轉、平移、翻轉等）迫使模型學習對這些變化的魯棒性。然而，對於高維圖數據，這種方法可能不切實際或效果有限。
基於約束的學習設計： 利用嚴格的數學約束或群論構建模型，確保其天然滿足所需的對稱性。
幾何深度學習在分子圖中的應用

在分子建模中，幾何深度學習為分子圖提供了工具，這些工具可以準確捕捉原子（節點）和鍵（邊）之間的關係。通過將每個原子作為節點，每條鍵作為邊，可以應用幾何深度學習原則來預測分子的性質、交互及行為。

圖神經網絡（GNNs）： GNNs 利用圖結構來傳遞信息，讓每個節點從其鄰居中學習，從而理解影響分子特性的關係。
處理旋轉和平移： 在分子性質（如結合親和力或反應潛能）預測中，模型需要對旋轉和平移保持不變。GNNs 可以通過基於結構的聚合方法實現這一點。
捕捉分層模式： 與卷積神經網絡（CNNs）識別低層次特徵（如邊緣）並逐步學習高層次形狀的方式類似，GNNs 能夠從單個原子學習，逐步捕捉更複雜的分子子結構。
等變性在物理模擬中的應用： 在分子動力學或分子交互模擬中，等變性至關重要，因為空間變換應該適當傳播到相關原子。幾何深度學習允許構建尊重這些特性的模型，特別適合高精度模擬。
幾何深度學習在藥物發現中的優勢

幾何深度學習在藥物發現和設計中的實用性體現在其處理分子圖和非結構化數據的能力上。

改進預測精度：幾何深度學習方法尊重分子的結構特性，因此能夠更準確地預測分子的性質和交互。
高效表示分子空間：GNN 能夠靈活處理複雜的圖結構數據，包括多種鍵類型與原子特徵。
增強對新化合物的泛化能力：幾何深度學習模型通過保持不變性與等變性，可以更好地適應新化合物，這對於發現新藥至關重要。
小結
幾何深度學習擴展了傳統深度學習，適應如圖和點雲這類複雜的非結構化數據。應用於分子圖時，它為分析、預測和模擬分子的性質與行為提供了強大的工具。通過開發魯棒且具有物理意義的模型，幾何深度學習推動了藥物發現的新進展。

圖神經網絡（GNNs）：結構、工作流程與應用
圖神經網絡（Graph Neural Networks, GNNs）是一類專為處理圖結構數據而設計的深度學習模型。與傳統神經網絡處理網格數據（如圖像或時間序列）不同，GNNs 專注於以節點（例如原子）和邊（例如化學鍵）表示的圖結構數據，這使其在分子圖、社交網絡和知識圖譜等複雜結構中應用廣泛。GNNs 的目標是捕捉圖中的關係與依賴性，預測與節點、邊甚至整個圖相關的特性或行為。

GNN 的關鍵應用

節點級預測：
應用：例如預測某特定節點（如分子中的原子）是否會參與活性位點的結合或參與化學反應。
實例：在蛋白質-小分子交互研究中，GNN 可預測分子中的哪個原子參與結合位點。
邊級（鏈路）預測：
應用：判斷節點間邊的存在性或強度（例如化學鍵的形成可能性）。
實例：基因組學中，預測可能與疾病相關的基因之間的潛在關聯。
圖級預測：
應用：為整個圖進行分類或性質預測，例如預測分子的毒性或是否能穿越血腦屏障。
實例：在藥物篩選中，基於整個分子結構預測其生物活性。
GNN 的一般工作流程

輸入數據與初始嵌入：
每個圖的節點以初始特徵向量開始，例如分子中的原子可以包括原子序數、電負性和雜化狀態等特徵。
這些特徵通過嵌入層轉化為高維空間中的向量，作為節點的初始狀態表示。
消息傳遞與鄰居聚合：
GNN 執行一系列消息傳遞步驟，在每個 GNN 層中，節點從其鄰居處收集信息。
鄰居信息（消息）通過可學習的權重矩陣進行變換，並通過聚合函數（例如求和或平均）融合，形成該節點的上下文表示。
多層消息傳遞：
每次消息傳遞層後，節點能“看到”其更遠的鄰居。例如，兩層後，每個節點包含了其兩跳鄰居的信息。
最終狀態與輸出生成：
一旦所有 GNN 層處理完成，每個節點達到其最終的隱層表示，該表示包含來自鄰居的信息。
根據任務性質，可以進行：
節點級任務：使用每個節點的最終隱層表示進行預測。
邊級任務：分析相鄰節點的最終表示，預測邊的屬性。
圖級任務：將所有節點的最終表示進行聚合，生成固定長度的圖級表示。
GNN 的示例工作流程

假設一個分子屬性預測任務：

輸入分子圖：
節點（原子）特徵：如原子質量、雜化狀態。
邊（鍵）特徵：如鍵類型（單鍵、雙鍵等）。
初始嵌入：
每個節點用特徵嵌入向量初始化。
消息傳遞與聚合：
每個節點從鄰居接收信息（例如，碳原子從相鄰的氧和氫原子接收消息）。
聚合鄰居消息後，更新節點表示。
多層處理：
經過多層 GNN，每個節點整合來自更遠節點的信息，例如兩跳或三跳鄰居。
最終輸出：
使用聚合的節點表示進行分子性質（如溶解度或毒性）預測。
GNN 層中的操作類型

圖上的卷積：
與 CNN 在網格上進行卷積類似，GNN 在每個節點的鄰域內進行卷積操作，聚合鄰居信息。
池化與讀出：
與 CNN 中的池化層類似，GNN 的池化有助於降維並聚合節點信息。可以應用於子圖內節點或整個圖上的池化。
正則化：
由於節點的度數可能差異較大，對聚合的信息進行正則化有助於平衡信息流，防止過於依賴高度連接的節點。
GNN 在分子建模與藥物發現中的優勢

處理複雜結構的靈活性：
GNN 能夠適應不規則、非歐幾里得的分子圖結構。
結構信息的高效利用：
GNN 內嵌與傳遞信息的方式自然尊重分子的空間與化學關係。
可擴展性：
GNN 的消息傳遞協議允許高效處理大型圖數據集，如虛擬篩選中的化學庫。
小結
圖神經網絡通過結合深度學習技術與圖結構數據的關係特徵，為分子建模提供了強大的框架。GNNs 的多功能性使其適用於藥物發現、材料科學和網絡分析等廣泛領域，尤其在需要深入理解數據中複雜關係的場景中表現卓越。

消息傳遞（Message Passing）在圖神經網絡中的應用
消息傳遞是圖神經網絡（GNNs）的核心操作，允許節點與其鄰居之間交換並聚合信息。這一過程使每個節點能夠結合來自其相鄰節點的特徵，構建出更豐富的上下文感知表示。消息傳遞是執行節點分類、鏈路預測和圖級屬性預測等圖結構任務的關鍵機制。

消息傳遞的主要步驟

消息生成：
對於圖中的每個節點，GNN 從其鄰居處創建消息。這通常通過使用可學習的權重矩陣，對每個鄰居節點的隱層表示進行變換。
舉例：對於一個黃色節點，其相鄰的粉色和灰色節點會通過權重矩陣變換生成消息向量，這些消息將被傳遞給黃色節點。
消息聚合：
下一步是將所有來自鄰居的消息聚合為一個向量，該向量反映所有鄰居的綜合影響。
常見的聚合策略包括：
求和聚合：將所有進入的消息加總。
均值聚合：計算所有消息的平均值，確保每個鄰居在聚合中有相等的權重。
最大池化：選取所有消息中最顯著的值，突出最重要的特徵。
聚合策略的選擇會影響 GNN 的性能。例如，對於度數差異較大的節點，正則化可能是必需的，以平衡信息流。
方向性與排列不變性：
在 GNN 中，鄰居沒有固有的“方向”或“位置”，因此必須保證 GNN 是排列不變的——鄰居消息的順序不應影響結果。
這一點通過對稱函數（如求和、均值或最大值）來實現，確保聚合方式與鄰居排列無關。
更新函數：
在聚合鄰居消息後，節點將使用更新函數結合自身的當前隱層表示與聚合消息，生成新的隱層表示。
更新函數的典型形式：

 ：分別是應用於節點自身和鄰居的可學習權重矩陣。
σ
σ：非線性激活函數（如 ReLU 或 tanh）。
非線性操作增加了模型的表達能力，使其能夠捕捉更複雜的節點間相互作用。
多層消息傳遞：
每次消息傳遞層之後，節點的“感受野”會擴展。例如：
一層消息傳遞後，節點可看到其直接鄰居的信息。
兩層後，可看到兩跳鄰居的信息（鄰居的鄰居）。
多層消息傳遞允許 GNN 捕捉圖中的長距依賴性，但過多層數可能導致信息稀釋或過平滑問題。
消息傳遞的示例應用

假設我們分析一個分子圖來預測化合物的溶解度：

節點初始化：
節點（原子）的特徵包括原子序數和電負性。
邊（鍵）的特徵包括鍵類型（單鍵、雙鍵等）。
消息傳遞：
每個節點從其鄰居接收消息。例如，碳原子從相鄰的氧和氫原子接收消息。
聚合消息後，更新碳原子的表示，使其反映鄰居的綜合影響。
多層擴展：
多層消息傳遞使每個節點能夠逐漸獲取來自更遠節點的信息，構建全局上下文。
模型輸出：
使用節點或圖級表示進行性質預測，例如預測化合物的溶解度。
消息傳遞在分子分析中的重要性

本地上下文的融合：
消息傳遞允許節點整合來自鄰居的信息，這對理解分子內局部化學環境至關重要。
可擴展性：
基於鄰居的聚合方式，使 GNN 能夠高效處理大型圖。
表達能力：
多層消息傳遞可捕捉節點間的長距依賴性，這對分子性質預測尤其重要。
小結
消息傳遞是 GNN 中的核心過程，使得每個節點能夠從其鄰居中獲取有意義的信息，並逐步構建其全局上下文表示。通過精心設計消息生成、聚合與更新步驟，GNN 能夠適應複雜的分子圖結構，為化學性質分析和藥物發現等領域提供強有力的工具。

如果您需要後續翻譯的部分（如節點更新或最終輸出等），請告訴我！

節點更新（Node Updates）在基礎圖神經網絡（GNN）中的應用
在基礎圖神經網絡中，節點更新是每一層消息傳遞過程中的關鍵部分。該機制允許每個節點通過反覆整合來自其鄰居的資訊，逐步構建更精緻的表示。

節點更新機制的逐步分解

節點嵌入初始化：
每個節點 

​	
 ，通常由輸入特徵（如原子序數或鍵類型）生成，或者通過嵌入層映射到高維空間。
計算隱層表示：
在每一層 
k
k 中，每個節點 
u
u 的隱層表示 

  是通過結合鄰居信息更新的，公式如下：

neighbor
⋅
Aggregate

​	
 ：鄰居嵌入的可學習權重矩陣。
Aggregate
Aggregate：鄰居信息的聚合函數（如求和或均值）。
σ
σ：非線性激活函數（如 ReLU）。
更新後的 
	
  代表節點的新狀態，結合了來自鄰居的上下文信息。
感受野的擴展：
每次應用一層 GNN 後，節點的“感受野”就會擴展：
層數 

k=1：節點僅聚合其直接鄰居的信息。
層數 

k=2：節點聚合來自二跳鄰居的信息（鄰居的鄰居）。
多層網絡可以捕捉長距離依賴性，使節點的表示能包含更廣泛的圖結構信息。
層數與信息擴散的平衡：
雖然更多層數允許更大的感受野，但過深的網絡可能導致以下問題：
信息稀釋：節點表示可能因過多層的聚合而過於平滑，難以區分節點特徵（稱為過平滑問題）。
計算成本增加：更多層會增加計算成本，且可能引發梯度消失或爆炸的問題。
通常，實踐中選擇 2-4 層可以在信息擴散和計算效率之間取得平衡。
節點更新的範例

考慮一個基於分子圖的溶解度預測任務：

初始表示：
節點（如原子）的初始特徵包括原子序數、鍵類型等。
消息聚合：
每個節點從其鄰居接收消息，通過聚合函數進行匯總。
非線性更新：
聚合消息後，節點的表示結合自身的初始嵌入進行非線性變換。
層數擴展：
重複上述過程，隨著層數增加，節點表示逐步融合來自遠距鄰居的信息。
GNN 最終輸出的應用
完成所有 GNN 層的消息傳遞後，我們獲得了每個節點的最終嵌入表示，該表示整合了節點自身及其鄰居的上下文信息。不同的任務需求決定了如何使用這些節點嵌入來生成有意義的預測。

關鍵任務

節點級別預測：
如果目標是預測單個節點的屬性或分類，我們可以直接使用其最終嵌入。
例如，在分子圖中，節點（原子）的嵌入可用於預測其是否參與某種化學反應。
邊級別預測：
邊級別預測涉及預測節點之間是否存在關聯（如化學鍵是否存在）。
方法包括計算節點嵌入之間的相似性（如餘弦相似度），或通過多層感知機（MLP）來進一步建模。
圖級別預測：
當需要對整個圖進行分類（如分子是否可溶）時，必須將節點嵌入聚合為單一向量，該向量捕捉整體圖結構信息。
圖級別聚合技術

求和聚合：
將所有節點嵌入相加，生成圖的綜合表示。
均值聚合：
計算節點嵌入的平均值，以消除因節點數量不同帶來的影響。
最大池化：
提取所有節點嵌入中最顯著的特徵值。
注意力機制：
使用注意力機制學習不同節點對任務的重要性，根據權重加權聚合節點嵌入。
虛擬節點：
引入一個虛擬節點，與圖中所有節點相連，通過消息傳遞聚合整圖信息。
小結
節點更新和輸出生成是 GNN 的關鍵步驟，這些步驟使模型能夠根據具體任務需求進行靈活調整。通過精心設計的聚合策略和嵌入生成方法，GNN 能夠處理複雜的圖結構數據，實現分子建模、社交網絡分析等多領域的應用。