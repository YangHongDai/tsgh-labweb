<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>計算生物學 | BioMed Communications</title>
    <link>http://localhost:1313/category/%E8%A8%88%E7%AE%97%E7%94%9F%E7%89%A9%E5%AD%B8/</link>
      <atom:link href="http://localhost:1313/category/%E8%A8%88%E7%AE%97%E7%94%9F%E7%89%A9%E5%AD%B8/index.xml" rel="self" type="application/rss+xml" />
    <description>計算生物學</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sun, 12 Jan 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu4369633333135054090.png</url>
      <title>計算生物學</title>
      <link>http://localhost:1313/category/%E8%A8%88%E7%AE%97%E7%94%9F%E7%89%A9%E5%AD%B8/</link>
    </image>
    
    <item>
      <title>計算生物學聊聊：Hidden Markov Chain (下)</title>
      <link>http://localhost:1313/post/markov2/</link>
      <pubDate>Sun, 12 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/markov2/</guid>
      <description>&lt;h2 id=&#34;quick-look&#34;&gt;Quick look&lt;/h2&gt;
&lt;p&gt;在上一章節，我們介紹了 Hidden Markov Model（HMM）的基本架構與 Forward Algorithm。本篇將進一步探討其他常見的 HMM 演算法，包括 Backward Algorithm、Forward-Backward Algorithm，以及解碼問題中的 Viterbi Algorithm，並說明其數學基礎及應用。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;backward-algorithm&#34;&gt;Backward Algorithm&lt;/h2&gt;
&lt;p&gt;Backward Algorithm 是 Forward Algorithm 的「對偶」，用於計算從時間點 $t$ 開始到序列結束生成觀察序列的機率。它主要用於與 Forward Algorithm 結合，進行參數估計和隱藏狀態的後驗分佈計算。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化(時間 $t = T$)：
$$
\beta_T(i) = 1, \quad \text{for } 1 \leq i \leq N
$$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;i 表示不同的隱藏狀態， 表示在最後一個時間點的&lt;code&gt;機率總和為 1&lt;/code&gt;，意即後面不會再有觀測值，機率已確定。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;遞推(時間 $t &amp;lt; T$)：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\beta_t(i) = \sum_{j=1}^N a_{ij} \cdot b_j(o_{t+1}) \cdot \beta_{t+1}(j), \quad 1 \leq i \leq N
$$&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\beta_t(i)$ 是在狀態 $s_i$ 且從時間點 $t+1$ 到序列結尾的觀察機率。&lt;/li&gt;
&lt;li&gt;$a_{ij}$ 是狀態 $s_i$ 到 $s_j$ 的轉移機率。&lt;/li&gt;
&lt;li&gt;$b_j(o_{t+1})$ 是狀態 $s_j$ 生成觀察值 $o_{t+1}$ 的機率。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其實就是forward algorithm 的計算方式由後往前算，因為每一個機率節點已經&lt;code&gt;繼承&lt;/code&gt;了前一個或後一個節點傳輸過來的資訊，因此可以接續往下計算。前向算法與後向算法的差別在於，一個機率取決於已經出現的觀察值，一個取決於未來值，即某一個時間點的前與後面的序列。&lt;/p&gt;
&lt;p&gt;此外，最重要的結論是不管前向還是後向，對總觀察機率的計算結果是一致的，因為總序列相同，條件的參數也相同。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;forward-backward-algorithm&#34;&gt;Forward-Backward Algorithm&lt;/h2&gt;
&lt;p&gt;前面講的forward algorithm 或是 backward algorithm 是用在觀測值機率的計算，但是如果要計算隱藏態的機率，就必須要靠兩者的結合。而隱藏狀態也是條件機率，但是前向和後向給的條件不同，也就是序列不同，所以兩者所評估的隱藏狀態分不會不一樣，因此必須要結合兩者來正確評估隱藏狀態的分佈。
Forward-Backward Algorithm 結合 Forward 和 Backward 的結果，用於計算隱藏狀態的後驗分佈（Posterior Distribution）。這在參數重估（如 Baum-Welch Algorithm）或狀態分析中非常重要。&lt;/p&gt;
&lt;h3 id=&#34;後驗機率計算公式&#34;&gt;後驗機率計算公式&lt;/h3&gt;
&lt;p&gt;給定觀察序列 $O = {o_1, o_2, \dots, o_T}$，隱藏狀態 $s_i$ 在時間 $t$ 出現的後驗機率為：&lt;/p&gt;
&lt;p&gt;$$
P(s_t = i \mid O, \lambda) = \frac{\alpha_t(i) \cdot \beta_t(i)}{P(O \mid \lambda)}
$$&lt;/p&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\alpha_t(i)$ 是 Forward Algorithm 在時間 $t$ 的結果。&lt;/li&gt;
&lt;li&gt;$\beta_t(i)$ 是 Backward Algorithm 在時間 $t$ 的結果。&lt;/li&gt;
&lt;li&gt;$P(O \mid \lambda)$ 是觀察序列的總機率，可用 Forward 或 Backward 計算：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
P(O \mid \lambda) = \sum_{i=1}^N \alpha_T(i)
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;viterbi-algorithm&#34;&gt;Viterbi Algorithm&lt;/h2&gt;
&lt;p&gt;Viterbi Algorithm 用於解碼問題，即在給定觀察序列的情況下，找出最可能的隱藏狀態序列（最短路徑問題）。&lt;/p&gt;
&lt;h3 id=&#34;數學公式&#34;&gt;數學公式&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;初始化(時間 $t=1$)：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\delta_1(i) = \pi_i \cdot b_i(o_1), \quad \psi_1(i) = 0, \quad 1 \leq i \leq N
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\delta_1(i)$ 表示狀態 $s_i$ 在時間 $t=1$ 的最優路徑機，也就是&lt;code&gt;機率較大&lt;/code&gt;的那條。&lt;/li&gt;
&lt;li&gt;$\psi_1(i)$ 是回溯指標，用於記錄上一個狀態。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;遞推(時間 $t &amp;gt; 1$)：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
\delta_t(i) = \max_{j=1}^N \big[\delta_{t-1}(j) \cdot a_{ji}\big] \cdot b_i(o_t), \quad 1 \leq i \leq N
$$&lt;/p&gt;
&lt;p&gt;$$
\psi_t(i) = \arg\max_{j=1}^N \big[\delta_{t-1}(j) \cdot a_{ji}\big]
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\delta_t(i)$ 是到時間 $t$ 並到達狀態 $s_i$ 的最優路徑機率。&lt;/li&gt;
&lt;li&gt;$\psi_t(i)$ 是到達 $s_i$ 的最可能上一個狀態。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;回溯：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;從最後一個時間點 $T$ 開始，找到最可能的終點狀態：&lt;/p&gt;
&lt;p&gt;$$
s_T^* = \arg\max_{i=1}^N \delta_T(i)
$$&lt;/p&gt;
&lt;p&gt;然後根據 $\psi$ 回溯最優隱藏狀態序列：&lt;/p&gt;
&lt;p&gt;$$
s_t^* = \psi_{t+1}(s_{t+1}^*), \quad t = T-1, T-2, \dots, 1
$$&lt;/p&gt;
&lt;p&gt;和forward-backward 演算法相比，Viterbi 在多數情況下會給出相似的計算，但因為Viterbi只會考慮最優解，所以會忽略其他路徑的貢獻，但forward-backward 演算法可能會給出機率較低的隱藏態。Forward-Backward 的後驗概率分佈反映了所有可能隱藏狀態的加權機率，而不是選擇單一路徑。因此，對某些時間點，它可能偏向於總體解釋力強但機率較低的狀態。&lt;/p&gt;
&lt;h2 id=&#34;其他演算法baum-welch-algorithm&#34;&gt;其他演算法：Baum Welch Algorithm&lt;/h2&gt;
&lt;p&gt;Baum-Welch 演算法是一種基於 EM (Expectation-Maximization) 框架的HMM參數學習方法，通過 Forward-Backward 演算法計算隱藏狀態的後驗分佈，並迭代更新初始分佈、轉移機率和觀察機率，以最大化觀察序列的對數似然值。其精髓在於將不可觀測的隱藏狀態以概率分佈的形式處理（軟標籤），適用於無監督學習的序列數據建模，但可能受初始值影響，易陷入局部最優。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;總結&#34;&gt;總結&lt;/h2&gt;
&lt;p&gt;本篇主要介紹了 HMM 的三個核心演算法：Backward Algorithm、Forward-Backward Algorithm 和 Viterbi Algorithm。這些演算法在生物資訊學中被廣泛應用，例如基因組注釋、蛋白質結構預測和序列比對。未來的篇章將繼續探討這些演算法的實際應用案例。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>計算生物學聊聊：分子表示法與圖神經網路</title>
      <link>http://localhost:1313/post/compbio_gnn/</link>
      <pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/compbio_gnn/</guid>
      <description>&lt;h2 id=&#34;quick-look&#34;&gt;Quick look&lt;/h2&gt;
&lt;p&gt;分子表示法（molecular representation）在計算化學中扮演重要的角色，它使化學家和數據科學家能夠將複雜的化學結構轉換成機器可理解的形式，用於數據存儲和計算分析。這些表示法在格式、易用性和應用場景上存在顯著的差異，每種表示法在特定類型的分析中具有其獨特的優勢和局限性，透過建構圖神經網路（Graph neural network, GNN）來預測分子的特性，這些表示法的差異會更為顯著。&lt;/p&gt;
&lt;p&gt;本篇筆記出自於美國麻省理工學院的計算生物學課程MLCB24。課程影片請看&lt;a href=&#34;https://www.youtube.com/watch?v=6gkIjo4Jb4E&amp;amp;t=220s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;這裡&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;常見的分子表示法&#34;&gt;常見的分子表示法&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;SMILES (簡化分子輸入線性表示系統)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SMARTS（SMILES 任意目標規範）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;InChI（國際化學標識符）&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Molecular graph (分子圖)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;接下來會根據每一種表示法做介紹：&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;smiles&#34;&gt;SMILES&lt;/h2&gt;
&lt;p&gt;SMILES（Simplified Molecular Input Line Entry System）是一種基於&lt;code&gt;字串&lt;/code&gt;的分子表示法，最初由美國環保署（EPA）開發，用於以緊密相連的線性格式捕捉分子的結構。目前為化學資訊學中最廣泛使用的小分子表示法之一。&lt;/p&gt;
&lt;h4 id=&#34;格式&#34;&gt;格式&lt;/h4&gt;
&lt;p&gt;例如，乙醇的 SMILES 表示為 &lt;code&gt;CCO&lt;/code&gt;（省略氫原子）。&lt;code&gt;字母&lt;/code&gt;和&lt;code&gt;數字&lt;/code&gt;表示原子與鍵類型（單鍵、雙鍵等），&lt;code&gt;括號&lt;/code&gt;則用來標示&lt;code&gt;分支&lt;/code&gt;結構。&lt;/p&gt;
&lt;h4 id=&#34;優點&#34;&gt;優點&lt;/h4&gt;
&lt;p&gt;SMILES 具有高度壓縮性（compact），容易被大多數化學資訊軟體讀取，適合用於資料庫存儲。&lt;/p&gt;
&lt;h4 id=&#34;限制&#34;&gt;限制&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;合成混淆&lt;/code&gt;：SMILES 字串靈活性高，容易生成，但這種靈活性導致許多語法有效的 SMILES 字串可能無法解碼成實際分子。
&lt;code&gt;立體化學&lt;/code&gt;：雖然 SMILES 可以包含立體化學資訊，但通常在實務上會被省略，當分子功能取決於立體資訊時，會導致問題產生。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;smartssmiles-任意目標規範&#34;&gt;SMARTS（SMILES 任意目標規範）&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;SMARTS&lt;/code&gt; 是根據 SMILES 來擴展的表示法，允許在 SMILES 字串中進行&lt;code&gt;模式匹配&lt;/code&gt;來識別特定的分子子結構。&lt;/p&gt;
&lt;h4 id=&#34;應用&#34;&gt;應用&lt;/h4&gt;
&lt;p&gt;SMARTS 對於化學資訊學中的&lt;code&gt;子結構搜索&lt;/code&gt;特別有用，例如識別&lt;code&gt;芳香環&lt;/code&gt;或其他分子&lt;code&gt;功能基團&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;格式-1&#34;&gt;格式&lt;/h4&gt;
&lt;p&gt;例如，芳香環可以用&lt;code&gt;c1cccccc1&lt;/code&gt;來表示。&lt;/p&gt;
&lt;h4 id=&#34;限制-1&#34;&gt;限制&lt;/h4&gt;
&lt;p&gt;儘管 SMARTS 在子結構搜索中功能強大，但比 SMILES 更&lt;code&gt;複雜&lt;/code&gt;，需要對&lt;code&gt;化學模式&lt;/code&gt;有更深入的理解才能有效使用。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;selfies自引用嵌入字串&#34;&gt;SELFIES（自引用嵌入字串）&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;SELFIES&lt;/code&gt; 是一種較新的表示法，主要在克服 SMILES 的一些限制。它更像是一種&lt;code&gt;分子編程語言&lt;/code&gt;，允許完整解構字串，&lt;code&gt;系統化生成分子&lt;/code&gt;，&lt;/p&gt;
&lt;h4 id=&#34;關鍵優勢&#34;&gt;關鍵優勢&lt;/h4&gt;
&lt;p&gt;可以很好的耐受錯誤，所有的SELFIES字串都可以解構成某特定分子，不會導致訊息的喪失，有利於機器學習。&lt;/p&gt;
&lt;h4 id=&#34;格式-2&#34;&gt;格式&lt;/h4&gt;
&lt;p&gt;例如，苯環可以表示成：&lt;code&gt;C1=CC=CC=C1&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;限制-2&#34;&gt;限制&lt;/h4&gt;
&lt;p&gt;SELFIES 雖然創新，但&lt;code&gt;較難閱讀&lt;/code&gt;，且需進一步改進以確保化學空間中的採樣沒有偏誤。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;inchi國際化學標識符&#34;&gt;InChI（國際化學標識符）&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;InChI&lt;/code&gt; 是一種IUPAC開發的標準化分子表示法，保證每個分子與其 InChI 字串一一對應。包含多層的分子特徵，如連結性、價電子、空間化學與異構物等。&lt;/p&gt;
&lt;h4 id=&#34;應用-1&#34;&gt;應用&lt;/h4&gt;
&lt;p&gt;InChI 在&lt;code&gt;資料庫搜索&lt;/code&gt;和&lt;code&gt;比較&lt;/code&gt;中特別有價值，因為它允許直接進行&lt;code&gt;分子比較&lt;/code&gt;，避免了因不同 SMILES 表示法導致的&lt;code&gt;多餘訊息&lt;/code&gt;。因為SMILE並沒有賦予分子獨特性，因此需要電腦解讀，增加計算負擔。&lt;/p&gt;
&lt;h4 id=&#34;關鍵優勢-1&#34;&gt;關鍵優勢&lt;/h4&gt;
&lt;p&gt;標準化的表示法，每一個表示法都對應到單一獨特的分子式。&lt;/p&gt;
&lt;h4 id=&#34;格式-3&#34;&gt;格式&lt;/h4&gt;
&lt;p&gt;例如，乙醇可以表示成：&lt;code&gt;1S/C2H6)/c1-2-3/h3H,2H2,1H3&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;限制-3&#34;&gt;限制&lt;/h4&gt;
&lt;p&gt;InChI 的&lt;code&gt;複雜性&lt;/code&gt;使其難以閱讀和解釋。由於簡潔性，許多人&lt;code&gt;更偏好用 SMILES 進行可視化&lt;/code&gt;。目前有方法將SMILES表達法InChI化，藉此增加InChI的可讀性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;分子圖&#34;&gt;分子圖&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;分子圖&lt;/code&gt;是一種基於&lt;code&gt;圖形&lt;/code&gt;的分子表示法，其中原子是頂點，鍵是邊。這種表示法捕捉了分子的所有信息，包括原子類型、鍵類型，甚至是立體化學。&lt;/p&gt;
&lt;h4 id=&#34;優點-1&#34;&gt;優點&lt;/h4&gt;
&lt;p&gt;分子圖全面地提供分子結構的完整描述，較為&lt;code&gt;直覺&lt;/code&gt;，尤其適用於基於圖的機器學習中的計算分析。&lt;/p&gt;
&lt;h4 id=&#34;限制-4&#34;&gt;限制&lt;/h4&gt;
&lt;p&gt;與基於字串的格式不同，分子圖不如 SMILES 那麼&lt;code&gt;緊密&lt;/code&gt;，也不適合快速搜索資料庫。分子圖更適合用於計算應用和視覺化，而非數據儲存。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;分子表示法比較&#34;&gt;分子表示法比較&lt;/h2&gt;
&lt;p&gt;圖一顯示不同分子表示法的總結。
















&lt;figure  id=&#34;figure-圖一-分子表示法比較&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig1&#34; srcset=&#34;
               /post/compbio_gnn/fig1_hu3479184427380367237.webp 400w,
               /post/compbio_gnn/fig1_hu2261907717937882707.webp 760w,
               /post/compbio_gnn/fig1_hu11170528079376645331.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/compbio_gnn/fig1_hu3479184427380367237.webp&#34;
               width=&#34;760&#34;
               height=&#34;540&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖一 分子表示法比較
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;smiles-表示法&#34;&gt;SMILES 表示法&lt;/h2&gt;
&lt;h4 id=&#34;原子與鍵&#34;&gt;原子與鍵&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;一般原子&lt;/code&gt;：在 SMILES 字串中，每個原子由其化學符號表示。大多數原子使用單個&lt;code&gt;大寫字母&lt;/code&gt;表示（例如，C 表示碳，O 表示氧）。一些原子需要兩個字母的組合（如 &lt;code&gt;Na 表示鈉，Cl 表示氯&lt;/code&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;芳香原子&lt;/code&gt;：在 SMILES 中，&lt;code&gt;小寫字母&lt;/code&gt;表示芳香化合物中的原子。例如，小寫的 c 表示&lt;code&gt;芳香碳&lt;/code&gt;，常見於&lt;code&gt;苯環&lt;/code&gt;中。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;鍵&lt;/code&gt;：&lt;code&gt;單鍵&lt;/code&gt;通常為簡化&lt;code&gt;省略&lt;/code&gt;，但也可使用單個破折號 &lt;code&gt;-&lt;/code&gt; 明確表示。&lt;code&gt;雙鍵&lt;/code&gt;用等號 &lt;code&gt;=&lt;/code&gt; 表示，&lt;code&gt;三鍵&lt;/code&gt;用井號 &lt;code&gt;#&lt;/code&gt; 表示。芳香鍵通常省略，因為小寫原子符號已隱含芳香性。分子組件的分離：句點 &lt;code&gt;.&lt;/code&gt; 用於表示分子中&lt;code&gt;不連接&lt;/code&gt;的部分，例如鹽或離子對。例：&lt;code&gt;Na.Cl 表示氯化鈉&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;鏈與分支&#34;&gt;鏈與分支&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;線性鏈&lt;/code&gt;：簡單的原子鏈以&lt;code&gt;直線順序&lt;/code&gt;表示。例如，乙醇的 SMILES 表示為 CCO，表示碳-碳-氧鏈。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;分支&lt;/code&gt;：SMILES 使用&lt;code&gt;括號&lt;/code&gt;表示從主鏈分支的結構。主鏈從括號前的原子開始繼續。例如，&lt;code&gt;異丙醇 (2-propanol or isopropanol)&lt;/code&gt;的 SMILES 表示為 &lt;code&gt;CC(O)C&lt;/code&gt;，其中 &lt;code&gt;(O)&lt;/code&gt; 表示&lt;code&gt;OH-&lt;/code&gt;分支。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;其他例子：&lt;/p&gt;
&lt;p&gt;CC(=O)C: 2-Propanone&lt;/p&gt;
&lt;p&gt;CC(CC)C: 2_Methylbutane&lt;/p&gt;
&lt;p&gt;CC(C)CC(=O): 2-Methylbutanal&lt;/p&gt;
&lt;p&gt;c1c(N)(=O)=O)cccc1: Nitrobenzene&lt;/p&gt;
&lt;p&gt;CC(C)(C)CC: 2,2-Dimethylbutane&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;環與環狀結構&#34;&gt;環與環狀結構&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;環閉合&lt;/code&gt;：SMILES 使用&lt;code&gt;數字&lt;/code&gt;標記環閉合。例如，&lt;code&gt;苯&lt;/code&gt;的表示為 &lt;code&gt;c1ccccc1&lt;/code&gt;，其中 &lt;code&gt;1&lt;/code&gt; 表示&lt;code&gt;第一和最後&lt;/code&gt;的碳原子相連以完成環。相同的數字表示開環與閉環的原子位置。鍵的類型著記在原子之後，但在數字之前。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;多重環&lt;/code&gt;：對於更複雜的環系統，使用額外的數字來表示分子內的每個環。例如，&lt;code&gt;萘&lt;/code&gt;的 SMILES 表示為 c1ccc2ccccc2c1，其中 1 和 2 標記了兩個融合的環 (圖二)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-圖二-萘-naphthalene的smiles表示法&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig2&#34; srcset=&#34;
               /post/compbio_gnn/fig2_hu10946339939307287139.webp 400w,
               /post/compbio_gnn/fig2_hu13962839815580817115.webp 760w,
               /post/compbio_gnn/fig2_hu7996518131002891555.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/compbio_gnn/fig2_hu10946339939307287139.webp&#34;
               width=&#34;292&#34;
               height=&#34;204&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖二 萘 (Naphthalene)的SMILES表示法
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;電荷&#34;&gt;電荷&lt;/h4&gt;
&lt;p&gt;電荷表示：SMILES 使用卷曲括號 &lt;code&gt;{}&lt;/code&gt; 和加號 &lt;code&gt;+&lt;/code&gt; 或減號 &lt;code&gt;-&lt;/code&gt; 表示原子的電荷。&lt;/p&gt;
&lt;h4 id=&#34;模稜兩可的名稱&#34;&gt;模稜兩可的名稱&lt;/h4&gt;
&lt;p&gt;若是比較容易讓人誤解的標示方法，用大括號 &lt;code&gt;[]&lt;/code&gt; 來區分，如Sc沒有框起來的話表示Sulfur與aromatic carbon，而[Sc]則表示Scandium。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;morgan-指紋機器學習中的分子結構編碼&#34;&gt;Morgan 指紋：機器學習中的分子結構編碼&lt;/h2&gt;
&lt;p&gt;Morgan 指紋（也稱為&lt;code&gt;環狀指紋&lt;/code&gt;）是一種強大的工具，可將分子結構轉換為&lt;code&gt;固定長度的二進制向量&lt;/code&gt;，使其非常適合於機器學習應用。與需要詳細結構數據的完整分子圖不同，Morgan 指紋提供了一種&lt;code&gt;計算效率更高&lt;/code&gt;的表示方式，捕捉每個原子周圍的結構特徵並以易於輸入機器學習模型的格式儲存。&lt;/p&gt;
&lt;h4 id=&#34;morgan-指紋的目的&#34;&gt;Morgan 指紋的目的&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;定量結構-活性關係（QSAR）建模&lt;/code&gt;：例如，預測分子的疏水性、溶解度或潛在生物活性。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;高通量篩選&lt;/code&gt;：在藥物發現中，用於快速篩選分子。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;主要優勢&#34;&gt;主要優勢&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;固定長度表示&lt;/code&gt;：每個分子無論大小都表示為特定長度的向量，與許多機器學習模型直接兼容。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;結構資訊封裝&lt;/code&gt;：通過編碼以原子為中心的子結構（達到&lt;code&gt;指定半徑&lt;/code&gt;），捕捉&lt;code&gt;局部化學環境&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;計算效率&lt;/code&gt;：這種表示方式&lt;code&gt;比生成完整分子圖更快&lt;/code&gt;，並且生成的指紋可快速用於機器學習。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;morgan-如何運作&#34;&gt;Morgan 如何運作？&lt;/h4&gt;
&lt;p&gt;生成 Morgan 指紋涉及一系列步驟，這些步驟專注於分子中的每個原子，並檢查其在指定半徑內的&lt;code&gt;局部結構&lt;/code&gt; (圖三)。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;以原子為中心的編碼&lt;/code&gt;： 每個&lt;code&gt;原子&lt;/code&gt;作為&lt;code&gt;中心點&lt;/code&gt;，檢查其周圍的子結構。這些子結構的細節取決於設定的&lt;code&gt;半徑&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;定義半徑：&lt;/p&gt;
&lt;p&gt;半徑 0：僅編碼原子本身。&lt;/p&gt;
&lt;p&gt;半徑 1：編碼原子及其鄰近原子。&lt;/p&gt;
&lt;p&gt;半徑 2：編碼原子、其鄰近原子及這些鄰近原子的鄰居。&lt;/p&gt;
&lt;p&gt;通常，使用半徑 2 即可捕捉足夠的細節，而不會導致向量過於龐大。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;將子結構映射到比特 (bit) 位置&lt;/code&gt;：每個環狀子結構都被編碼為一個&lt;code&gt;二進制向量（bit string）&lt;/code&gt;，其中特定特徵（例如原子、鍵、環）的存在記錄為&lt;code&gt;1&lt;/code&gt;，缺失記錄為&lt;code&gt;0&lt;/code&gt;。半徑決定了圍繞中心原子的原子層數（例如，半徑為2時包括距離中心原子兩鍵以內的原子和鍵）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;子結構碰撞&lt;/code&gt;：子結構被哈希(hash)轉換為固定長度的指紋（例如1024位），這可能導致哈希碰撞，即多個子結構可能映射到相同的位。可以考慮增加長度來解決。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-圖三-morgan-fingerprinthttpstowardsdatasciencecoma-practical-introduction-to-the-use-of-molecular-fingerprints-in-drug-discovery-7f15021be2b1&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig3&#34; srcset=&#34;
               /post/compbio_gnn/fig3_hu1804110335273990854.webp 400w,
               /post/compbio_gnn/fig3_hu17041954323525736801.webp 760w,
               /post/compbio_gnn/fig3_hu9009013187830519231.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/compbio_gnn/fig3_hu1804110335273990854.webp&#34;
               width=&#34;760&#34;
               height=&#34;171&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;a href=&#34;https://towardsdatascience.com/a-practical-introduction-to-the-use-of-molecular-fingerprints-in-drug-discovery-7f15021be2b1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;圖三 Morgan fingerprint&lt;/a&gt;
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;morgan-指紋生成範例&#34;&gt;Morgan 指紋生成範例&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;第一步：從分子內的某原子開始。&lt;/li&gt;
&lt;li&gt;第二步：根據特定的半徑來建構子結構。&lt;/li&gt;
&lt;li&gt;第三步：使用Hash table來將子結構轉換成獨特的比特編號。&lt;/li&gt;
&lt;li&gt;第四步：針對每一個原子完成以上步驟，產生一個二元分子指紋，表示整個分子。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;以乙醇cco為例&#34;&gt;以乙醇（CCO）為例&lt;/h4&gt;
&lt;p&gt;每個碳和氧原子作為中心點，評估其半徑 2 內的子結構。&lt;/p&gt;
&lt;p&gt;這將產生以下信息：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;原子 1：第一個碳及其鄰居（第二個碳和氧）。&lt;/li&gt;
&lt;li&gt;原子 2：第二個碳及其鄰居（第一個碳和氧）。&lt;/li&gt;
&lt;li&gt;原子 3：氧及其鄰近的碳。
每個原子和子結構會映射到指紋中，形成唯一表示乙醇結構的比特向量。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;morgan-指紋的優點&#34;&gt;Morgan 指紋的優點&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;對結構改變非常敏感，結構的些微修飾都可以被捕捉。&lt;/li&gt;
&lt;li&gt;效率高。&lt;/li&gt;
&lt;li&gt;廣泛使用於常見化學資訊學的工具中，如&lt;code&gt;RDKit&lt;/code&gt;，也常用在視覺篩選與相似性搜索中。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;半徑與比特向量長度的平衡&#34;&gt;半徑與比特向量長度的平衡&lt;/h4&gt;
&lt;p&gt;半徑增加的影響：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;半徑越大，捕捉的子結構越詳細，但需要更大的向量以避免碰撞。&lt;/li&gt;
&lt;li&gt;半徑 2 提供了適度的細節，廣泛用於化學資訊學。&lt;/li&gt;
&lt;li&gt;半徑 3 或更大通常僅在需要非常細粒度結構細節時使用，但會顯著增加計算需求和複雜性。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;向量長度&#34;&gt;向量長度&lt;/h4&gt;
&lt;p&gt;常用長度為 1024 或 2048 比特。更大的向量幫助減少哈希碰撞，但在數據集較小時可能導致稀疏性問題。&lt;/p&gt;
&lt;h4 id=&#34;在機器學習中的解釋與應用&#34;&gt;在機器學習中的解釋與應用&lt;/h4&gt;
&lt;p&gt;Morgan 指紋將複雜的分子結構轉換為向量空間表示，其中具有相似拓撲特徵的分子具有相似的指紋。結果向量可用於以下機器學習模型：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;隨機森林&lt;/code&gt;：適合特徵豐富的數據集，向量直接表示分子特徵。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;多層感知機（MLP）&lt;/code&gt;：能有效處理 Morgan 指紋，學習數據中的非線性模式。&lt;/li&gt;
&lt;li&gt;其他演算法：包括支持向量機（SVM）和邏輯回歸在內的任何處理二進制或數值向量的演算法均可使用 Morgan 指紋。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;限制與考量&#34;&gt;限制與考量&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;不可逆&lt;/code&gt;：指紋無法反向解碼為原始分子。&lt;/li&gt;
&lt;li&gt;碰撞問題：不同的分子結構可能映射到相同的比特位置，尤其是在&lt;code&gt;較小的比特向量&lt;/code&gt;或&lt;code&gt;大分子&lt;/code&gt;時。&lt;/li&gt;
&lt;li&gt;不適用於大生物分子：對於&lt;code&gt;非常大的生物分子（如蛋白質）&lt;/code&gt;，Morgan 指紋可能不適用，因為結構的複雜性超出了其表達能力。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;分子圖化學結構的進階表示&#34;&gt;分子圖：化學結構的進階表示&lt;/h2&gt;
&lt;p&gt;分子圖是一種靈活且精細的方式，能夠以數學形式表示分子，特別是在指紋&lt;code&gt;無法捕捉足夠結構細節&lt;/code&gt;時尤其有用。與比特向量指紋不同，分子圖提供了分子結構的&lt;code&gt;直接映射&lt;/code&gt;，將每個原子作為&lt;code&gt;節點 (node)&lt;/code&gt;，每條鍵作為&lt;code&gt;邊 (edge)&lt;/code&gt;。這種基於結構的表示允許更高的&lt;code&gt;特異性&lt;/code&gt;和數據的豐富性，使其成為&lt;code&gt;圖神經網絡（Graph Neural Networks, GNNs）&lt;/code&gt;的最佳輸入，尤其適用於需要深入探索原子間的關係時，例如定量QSAR和藥物設計。&lt;/p&gt;
&lt;h4 id=&#34;分子圖的結構&#34;&gt;分子圖的結構&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;節點與邊&lt;/code&gt;：在分子圖中，每個&lt;code&gt;節點表示一個原子&lt;/code&gt;，每條&lt;code&gt;邊表示一條化學鍵&lt;/code&gt;。這種結構捕捉了分子內的原子類型及鍵類型（單鍵、雙鍵、三鍵或芳香鍵），能夠詳細描述化學關係。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;節點標籤&lt;/code&gt;：每個節點可以攜帶標籤或類型（例如，碳用 C 表示，氮用 N 表示），以區分不同的原子類型。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;邊標籤&lt;/code&gt;：邊可以標示鍵的類型（如單鍵、雙鍵、三鍵等）。這在分子圖中尤為重要，因為鍵類型對分子的化學行為和特性有著重要影響。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;圖的種類&#34;&gt;圖的種類&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;方向性&lt;/code&gt;：在大多數情況下，分子圖是&lt;code&gt;無向 (undirected)&lt;/code&gt;的，因為&lt;code&gt;化學鍵通常沒有方向性&lt;/code&gt;。但在某些情境下，如&lt;code&gt;化學反應&lt;/code&gt;網絡中，可以使用&lt;code&gt;有向圖 (directed)&lt;/code&gt;來表示從反應物到產物的轉化流程。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;圖標籤&lt;/code&gt;：原子和鍵都被標示，說明原子和鍵的類型，在對於需要化學分子細節的探討中很重要。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;加權圖&lt;/code&gt;：雖然在基本分子圖中不常使用，但可以引入&lt;code&gt;加權邊&lt;/code&gt;以指示&lt;code&gt;鍵強度&lt;/code&gt;、相互作用強度或其他結構行為的&lt;code&gt;先驗知識&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;對稱性&lt;/code&gt;：對於無向圖，鄰接矩陣是對稱的；對於有向圖，則是非對稱的，反映每條邊的方向性。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;分子圖的表示方法&#34;&gt;分子圖的表示方法&lt;/h4&gt;
&lt;h4 id=&#34;鄰接矩陣-adjacency-matrix&#34;&gt;鄰接矩陣 (Adjacency Matrix)：&lt;/h4&gt;
&lt;p&gt;鄰接矩陣提供了一種表格式的圖表示，其中每個單元格表示原子之間&lt;code&gt;是否存在鍵（或鍵的類型）&lt;/code&gt;。例如，若原子
(i,j) 的值為 1（或表示鍵類型的整數）；否則為 0。&lt;/p&gt;
&lt;h4 id=&#34;鄰接列表-adjacency-list&#34;&gt;鄰接列表 （Adjacency List）&lt;/h4&gt;
&lt;p&gt;在處理大型圖（如社交網絡或大規模數據集）時比矩陣更高效。每個原子只保存與其直接相連的原子清單，大大減少稀疏網絡中的存儲需求。&lt;/p&gt;
&lt;h4 id=&#34;稀疏矩陣表示&#34;&gt;稀疏矩陣表示：&lt;/h4&gt;
&lt;p&gt;另一種選擇是使用稀疏矩陣，只存儲非零值（即存在鍵的原子對），進一步降低內存使用量。&lt;/p&gt;
&lt;h4 id=&#34;圖的可視化&#34;&gt;圖的可視化：&lt;/h4&gt;
&lt;p&gt;分子圖也可以被可視化，提供直觀的方式來檢查分子結構、理解其複雜性並排查表示中的問題。&lt;/p&gt;
&lt;h4 id=&#34;分子圖的應用與優勢&#34;&gt;分子圖的應用與優勢&lt;/h4&gt;
&lt;h4 id=&#34;完整的結構編碼分子圖保留了分子的完整拓撲結構允許對其特性和相互作用進行更深入的檢查&#34;&gt;完整的結構編碼：分子圖保留了分子的完整拓撲結構，允許對其特性和相互作用進行更深入的檢查。&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;與圖神經網絡（GNNs）的兼容性：分子圖可以與 GNNs 無縫集成，後者專門設計用於處理圖結構數據。&lt;/li&gt;
&lt;li&gt;強化的預測模型：基於分子圖構建的 GNN 模型能夠更準確地預測分子的各種特性，如生物活性、毒性、溶解度和結合親和力。&lt;/li&gt;
&lt;li&gt;消息傳遞：在 GNN 中，每個節點通過一種稱為消息傳遞的迭代過程與其鄰居進行通信。這允許每個節點聚合鄰近節點的信息，有效地捕捉其分子環境的影響。&lt;/li&gt;
&lt;li&gt;分層結構：與傳統神經網絡類似，GNN 有多層結構，每層允許圖捕捉分子中越來越遠的關係。&lt;/li&gt;
&lt;li&gt;可定制性：GNN 可以納入方向性和邊權重的設計，特別適合於處理具有專門相互作用的分子結構。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;其他圖應用&#34;&gt;其他圖應用&lt;/h3&gt;
&lt;p&gt;雖然分子圖是化學中的自然選擇，但其原則和技術可廣泛應用於其他與圖相關的領域，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;社交網絡：節點表示個體，邊表示聯繫（通常是有向的）。&lt;/li&gt;
&lt;li&gt;通訊網絡：路由信息，其中節點表示服務器或路由器，邊表示數據流路徑。&lt;/li&gt;
&lt;li&gt;生物網絡：基因與蛋白質的交互網絡，節點表示基因或蛋白質，邊表示相互作用或調控關係。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;運用分子圖於藥物開發領域&#34;&gt;運用分子圖於藥物開發領域&lt;/h2&gt;
&lt;p&gt;分子圖在藥物發現和開發的各個階段都不可或缺，能夠精準捕捉並操作分子的完整結構。以下是分子圖如何顯著提升藥物開發流程的幾種方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;化學相似性搜索 （Chemical similarity searching）&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;當一種化合物顯示出與特定靶點的良好結合親和力時，研究人員通常會尋找與之結構相似的化合物，因為它們可能具有類似的活性。通過分子圖，我們可以編碼已知化合物的結構特徵，並在包含數百萬化合物的大型化學庫中搜索類似結構。&lt;/li&gt;
&lt;li&gt;研究人員可以優先選擇較小且更具針對性的分子集進行初步測試，從而減少大規模篩選的成本和資源使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;code&gt;定量結構-活性關係（QSAR）建模&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;QSAR 模型使用分子圖來預測各種生物化學和藥代動力學特性。例如，可以基於分子結構預測以下屬性：&lt;/li&gt;
&lt;li&gt;溶解度&lt;/li&gt;
&lt;li&gt;血腦屏障的滲透性&lt;/li&gt;
&lt;li&gt;ADME（吸收、分布、代謝、排泄）&lt;/li&gt;
&lt;li&gt;毒性&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;code&gt;基於結構的藥物設計&lt;/code&gt;
分子圖允許進行基於結構的藥物設計，通過表現完整的分子結構，支持更準確的分子-靶標作用模擬與預測。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;研究人員可以利用基於分子圖的表示法來模擬&lt;code&gt;結合能量&lt;/code&gt;及&lt;code&gt;交互動態&lt;/code&gt;，設計專門與目標結合的化合物。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;卷積神經網絡-cnns&#34;&gt;卷積神經網絡 (CNNs)&lt;/h2&gt;
&lt;p&gt;為更直觀地理解GNNs，可以先考慮CNNs的結構與功能。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;CNN 處理 2D 網格數據&lt;/code&gt;: 以像素為單位：CNN 將每個像素視為一個單位，並與相鄰像素進行連接（垂直或水平），從而學習局部模式（如邊緣、梯度和紋理）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;層級學習&lt;/code&gt;：隨著網絡層數的增加，CNN 將這些&lt;code&gt;初級&lt;/code&gt;特徵&lt;code&gt;聚合為更高級模式&lt;/code&gt;，最終能夠識別複雜對象（例如貓、狗或汽車）。&lt;/li&gt;
&lt;li&gt;從 CNN 到&lt;code&gt;幾何深度學習（GDL）的過渡&lt;/code&gt;: 將 CNN 在結構化數據（如影像）上的成功&lt;code&gt;推廣到非結構化&lt;/code&gt;、&lt;code&gt;非歐幾里得數據&lt;/code&gt;，如&lt;code&gt;圖&lt;/code&gt;和&lt;code&gt;流形&lt;/code&gt; (graphs, meshes and point clouds)。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;而圖與網格或矩陣不同，因其&lt;code&gt;缺乏固定的節點排列&lt;/code&gt;且&lt;code&gt;連接多樣化&lt;/code&gt;，因此需要專門的神經網絡架構，因此才有圖神經網路的角色出現。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;invariance-與-equivariance&#34;&gt;Invariance 與 Equivariance&lt;/h2&gt;
&lt;p&gt;在深度學習中，Invariance（不變性）與 Equivariance（等變性）是兩個非常重要的概念，特別是在處理結構化數據（例如圖像、序列、圖）時，對模型的性能和泛化能力有著深遠的影響。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invariance: 不變性指的是模型或函數對某些輸入變換保持輸出不變的特性。如果f(x)是某個模型或函數，針對某個變換T，不變性表示：&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
f(T(x))=f(x)
$$
&lt;/div&gt;
&lt;p&gt;如圖四，貓的圖片在轉換之後，模型仍然能偵測為貓。或是一個模型在預測分子溶解度時應該對分子的&lt;code&gt;旋轉&lt;/code&gt;或&lt;code&gt;平移&lt;/code&gt;保持不變，因為這些變換&lt;code&gt;不影響分子的溶解性&lt;/code&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Equivariance: 等變性指的是模型或函數對某些輸入變換的輸出也發生相應的變換。如果f(x)是某個模型或函數，針對某個變換T，等變性表示：&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
f(T(x))=T(f(x))
$$
&lt;/div&gt;
&lt;p&gt;換句話說，輸入經過某種變化後，輸出的結果應該跟著同步變化。例如，分子動力學模擬中，對參考框架的旋轉應該導致原子位置與動量的相應旋轉。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-圖四&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig4&#34; srcset=&#34;
               /post/compbio_gnn/fig4_hu18150330024369147487.webp 400w,
               /post/compbio_gnn/fig4_hu7306947348480769975.webp 760w,
               /post/compbio_gnn/fig4_hu5704989358987084869.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/compbio_gnn/fig4_hu18150330024369147487.webp&#34;
               width=&#34;760&#34;
               height=&#34;329&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖四
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;圖神經網路&#34;&gt;圖神經網路&lt;/h2&gt;
&lt;p&gt;圖神經網絡是一類專為處理圖結構數據而設計的深度學習模型。與傳統神經網絡處理網格數據（如圖像或時間序列）不同，GNNs 專注於以節點（例如原子）和邊（例如化學鍵）表示的圖結構數據，這使其在分子圖、社交網絡和知識圖譜等複雜結構中應用廣泛。GNNs 的目標是捕捉圖中的關係與依賴性，預測與節點、邊甚至整個圖相關的特性或行為。&lt;/p&gt;
&lt;h4 id=&#34;關鍵概念&#34;&gt;關鍵概念&lt;/h4&gt;
&lt;p&gt;圖神經網路可以學習如何表達以圖為結構的數據，並且可以利用節點和邊的關係來做預測。&lt;/p&gt;
&lt;h4 id=&#34;gnn-的關鍵應用&#34;&gt;GNN 的關鍵應用&lt;/h4&gt;
&lt;p&gt;廣泛使用於&lt;code&gt;化學資訊學&lt;/code&gt;、生物資訊學與&lt;code&gt;社群網路&lt;/code&gt;分析。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;節點級預測&lt;/code&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;應用：例如預測某特定節點（如分子中的原子）是否會參與活性位點的結合或參與化學反應。&lt;/li&gt;
&lt;li&gt;實例：在蛋白質-小分子交互研究中，GNN 可預測分子中的&lt;code&gt;哪個原子參與結合位點&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;code&gt;邊級（鏈路）預測&lt;/code&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;應用：判斷節點間邊的存在性或強度（例如化學鍵的形成可能性）。&lt;/li&gt;
&lt;li&gt;實例：基因組學中，預測可能與疾病相關的基因之間的潛在關聯。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;code&gt;圖級預測&lt;/code&gt;：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;應用：為整個圖進行分類或性質預測，例如預測&lt;code&gt;分子的毒性&lt;/code&gt;或是&lt;code&gt;否能穿越血腦屏障&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;實例：在藥物篩選中，基於&lt;code&gt;整個分子結構&lt;/code&gt;預測其生物活性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;gnn-的一般工作流程&#34;&gt;GNN 的一般工作流程&lt;/h4&gt;
&lt;p&gt;GNN 的工作流程通常包括以下幾個階段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;輸入數據與初始嵌入&lt;/code&gt;: 圖中的每個&lt;code&gt;節點&lt;/code&gt;都有一些初始輸入特徵。例如，在分子應用中，每個節點可能表示一個原子，其特徵可能包括原子序數、電荷狀態等。這些初始特徵被嵌入到一個高維空間中的潛在表示中（latent representation），以捕捉每個節點的初始狀態。
















&lt;figure  id=&#34;figure-圖五-圖神經網路的節點特徵嵌入&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig5&#34; srcset=&#34;
               /post/compbio_gnn/fig5_hu2388238815147713275.webp 400w,
               /post/compbio_gnn/fig5_hu5675022451590598209.webp 760w,
               /post/compbio_gnn/fig5_hu3447441218360307289.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/compbio_gnn/fig5_hu2388238815147713275.webp&#34;
               width=&#34;760&#34;
               height=&#34;292&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖五 圖神經網路的節點特徵嵌入
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通過 GNN 層進行&lt;code&gt;信息傳遞 (Message Passing)&lt;/code&gt;: 嵌入後，GNN 在多層網絡中進行一系列的消息傳遞（message passing）步驟。這一過程類似於 CNN 中的卷積操作，CNN 是從&lt;code&gt;鄰近像素中聚合信息&lt;/code&gt;，而 GNN 則是從&lt;code&gt;相鄰節點中聚合信息&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;聚合與更新: 在每一層 GNN 中，每個節點都從其鄰居處接收訊息。節點將這些訊息聚合起來，與自身的潛在向量結合後&lt;code&gt;更新其狀態&lt;/code&gt;。這種聚合方法可以是&lt;code&gt;求和（sum&lt;/code&gt;）、&lt;code&gt;均值（mean）&lt;/code&gt;、或&lt;code&gt;最大池化（max pooling&lt;/code&gt;），具體取決於任務需求。
以下是一些常見的聚合技術：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;總和聚合(Sum Aggregation)&lt;/code&gt;：透過將所有節點的representation相加，我們可以獲得一個&lt;code&gt;單一的向量&lt;/code&gt;，反映來自所有節點的&lt;code&gt;累積信息&lt;/code&gt;。這種方法在節點數量在&lt;code&gt;不同圖之間相近時&lt;/code&gt;效果不錯，但如果某些圖比其他圖大得多，可能會導致偏差。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;平均聚合(Mean Aggregation)&lt;/code&gt;：通過對節點向量取平均值，這種方法在聚合過程中進行了歸一化，確保圖的大小（節點數量）不會影響結果。當處理大小不同的圖時，平均聚合特別有用，因為它可以調整節點數量之間的差異。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;最大池化(Max Pooling)&lt;/code&gt;：在這種方法中，我們從所有節點向量的&lt;code&gt;每個位置中取最大值&lt;/code&gt;，捕捉到最顯著的特徵值。這種方法能夠突出圖中最具代表性的特徵，但可能會&lt;code&gt;忽略&lt;/code&gt;一些重要的細微特徵，特別是當其他節點包含較低但關鍵的值時。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;注意力機制(Attention Mechanisms)&lt;/code&gt;：基於注意力機制的方法允許我們根據節點對任務的重要性，對每個節點的貢獻賦予不同的權重。模型會自動學習這些權重，從而自適應地突出關鍵節點，是一種強大的方法來優先考慮圖中的某些區域。例如，在分子圖中，注意力機制可以對重要的功能基團賦予更高的權重，以便在預測化學性質時更加精準。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;全局節點或虛擬節點(Global Nodes or Virtual Nodes)&lt;/code&gt;：在一些進階的 GNN中，會引入一個&lt;code&gt;全局節點&lt;/code&gt;或&lt;code&gt;虛擬節點&lt;/code&gt;，該節點與圖中的所有其他節點相連。在信息傳遞（message-passing）過程中，這個節點會聚合來自整個圖的所有信息，作為一個中心樞紐。到最後，這個虛擬節點的潛在向量（latent vector）就成為整個圖的表示，捕捉了整個網絡的特徵。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-圖六-訊息的結合&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig6&#34; srcset=&#34;
               /post/compbio_gnn/fig6_hu17702982825052260044.webp 400w,
               /post/compbio_gnn/fig6_hu18171683510162612183.webp 760w,
               /post/compbio_gnn/fig6_hu17719637959162410375.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/compbio_gnn/fig6_hu17702982825052260044.webp&#34;
               width=&#34;760&#34;
               height=&#34;246&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖六 訊息的結合
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-圖七-節點訊息的更新&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig7&#34; srcset=&#34;
               /post/compbio_gnn/fig7_hu14204850261544369576.webp 400w,
               /post/compbio_gnn/fig7_hu9938346904168491431.webp 760w,
               /post/compbio_gnn/fig7_hu296375659254389028.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/compbio_gnn/fig7_hu14204850261544369576.webp&#34;
               width=&#34;760&#34;
               height=&#34;261&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖七 節點訊息的更新
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;節點的更新公式：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
h_u^{(k)} = \sigma \left( W_{\text{self}}^{(k)} h_u^{(k-1)} + W_{\text{neigh}}^{(k)} \sum_{v \in \mathcal{N}_u} h_v^{(k-1)} + b^{(k)} \right)
$$
&lt;/div&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
h_u^{(k-1)} \in \mathbb{R}^{d^{(k-1)}}: Node-embeddings
$$
&lt;/div&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
W_{\text{self}}^{(k)}, W_{\text{neigh}}^{(k)} \in \mathbb{R}^{d^{(k)} \times d^{(k-1)}}: Learnable-parameters
$$
&lt;/div&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
b^{(k)} \in \mathbb{R}^{d^{(k)}}: Bias-term
$$
&lt;/div&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$\sigma: Elementwise-non-linearity  (e.g., a \tanh or ReLU)$$
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;更新機制&lt;/p&gt;
&lt;p&gt;Step 1: 每個節點先從鄰居中收集信息（聚合鄰居特徵）。&lt;/p&gt;
&lt;p&gt;Step 2: 將聚合後的鄰居特徵與自身特徵結合（線性變換 + 偏置項）。&lt;/p&gt;
&lt;p&gt;Step 3: 應用激活函數，生成該節點在新層的嵌入特徵。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;多層結構: 信息通過&lt;code&gt;多層傳遞&lt;/code&gt;，每層使節點可以&lt;code&gt;看到&lt;/code&gt;圖中&lt;code&gt;更遠的鄰居&lt;/code&gt;。例如，經過兩層後，每個節點可以融入來自其&lt;code&gt;兩跳&lt;/code&gt;鄰居的信息。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最終狀態與輸出生成: 當圖經過多層 GNN 處理後，節點達到最終狀態，該狀態包含從周圍節點學到的信息。這些最終狀態可以用於生成多種預測：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;節點級任務&lt;/code&gt;：使用每個節點的最終狀態進行預測。當我們需要為單個節點分類或預測屬性時，可以直接使用每個節點的最終潛在表示（latent representation）。例如，假設我們有一個分子圖，並且已知每個原子的分子屬性，但對某個特定原子（節點）缺乏相關信息，我們可以將該未知節點的潛在向量輸入分類器，來預測所需的屬性，例如該原子是否參與結合位點，或者是否與某些分子相互作用。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;邊級任務&lt;/code&gt;：分析相鄰節點最終狀態之間的關係。連結預測的目標是預測節點之間的連接（邊）的存在性或強度，這在&lt;code&gt;社交網絡&lt;/code&gt;或&lt;code&gt;生物網絡&lt;/code&gt;中非常有用，可以用來推斷新的關係。例如，在基因組學中，我們可能已知與某種疾病相關的一組基因，並希望通過檢查它們在生物途徑中的連接性，來預測其他潛在的基因。這可以通過以下方式實現：將兩個節點的潛在向量進行相似性測量（例如餘弦相似度）或學習函數，來預測是否存在一條邊。更複雜的情況下，將兩個節點的表示組合後輸入多層感知器（MLP），以進行關係的預測。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;圖級任務&lt;/code&gt;：將所有節點的最終狀態池化成單一圖表示，用於&lt;code&gt;分類&lt;/code&gt;或&lt;code&gt;回歸&lt;/code&gt;。在某些情況下，我們需要對整個圖進行單一的預測，例如分子的溶解度或毒性。這時需要將所有節點的信息聚合成一個&lt;code&gt;固定長度的向量&lt;/code&gt;，該向量能夠捕捉整個圖的結構和特徵。例如：可以使用聚合技術（如平均聚合、總和聚合或注意力機制）來匯總節點的表示，生成代表整體圖特徵的向量。
然後，將該圖級表示作為輸入，用於進行&lt;code&gt;分類&lt;/code&gt;或迴歸任務。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;擴大感受野&#34;&gt;擴大感受野&lt;/h4&gt;
&lt;p&gt;每當我們應用一層 GNN層時，實際上我們就增加了每個節點的&lt;code&gt;感受野 (receptive filed)&lt;/code&gt;。起初，一個節點的感受野僅包括&lt;code&gt;它自己&lt;/code&gt;。然而，在第一層之後，該節點的表示（representation）將會結合來自其直接鄰居的信息。經過第二層後，該節點的表示將會包含來自兩跳 (K-hops=2) 鄰居（即鄰居的鄰居）的信息，依此類推。這種擴展意味著節點可以逐漸從圖中更大的區域累積信息。
例如，在分子圖中，一個碳原子的感受野起初可能僅包括直接鍵合的原子（例如一個相鄰的氧原子）。而經過兩層 GNN 層後，該碳原子可以結合來自兩個鍵距離的原子的信息，提供更多的化學訊息。&lt;/p&gt;
&lt;h4 id=&#34;層數深度與信息擴散&#34;&gt;層數深度與信息擴散&lt;/h4&gt;
&lt;p&gt;雖然看似增加層數可以最大化節點的感受野，但更深的網絡層數也會帶來一些問題：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;訊息稀釋(Information Dilution)&lt;/code&gt;：隨著層數的增加，節點表示可能會&lt;code&gt;過度混合（overly blended）&lt;/code&gt;，失去原本的特徵，從而&lt;code&gt;難以區分不同的節點&lt;/code&gt;。這種現象通常被稱為&lt;code&gt;過平滑（oversmoothing）&lt;/code&gt;，在處理複雜任務時可能導致性能下降。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;計算成本(Computational Costs)&lt;/code&gt;：增加層數需要更多的計算資源，同時也會提高訓練過程中出現&lt;code&gt;梯度消失&lt;/code&gt;或&lt;code&gt;梯度爆炸&lt;/code&gt;問題的風險，從而使訓練變得更加困難。
因此，在許多實際應用中，使用&lt;code&gt;有限層數的 GNN（例如 2-4 層）&lt;/code&gt;是更為有效的策略。這種方法在計算效率與每個節點能夠融合的信息深度之間取得了&lt;code&gt;平衡&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;p&gt;GNN 層中的操作旨在將卷積操作推廣到圖結構，其中空間結構由節點之間的邊定義，而不是固定的空間坐標。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;圖上的卷積(Convolution on Graphs)&lt;/code&gt;:在 CNN 中，卷積在固定的網格上進行；而在 GNN 中，卷積基於每個節點的鄰域進行。這種局部特徵的聚合使得每個節點可以從其鄰居中學習，同時保留圖的固有結構。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;池化與讀出(Pooling and Readout)&lt;/code&gt;: 與 CNN 中的池化層類似，GNN 的池化用於&lt;code&gt;減少維度並聚合節點信息&lt;/code&gt;。池化可以應用於子圖內的節點，也可以應用於整個圖，用於生成圖級輸出。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;正規化(Normalization)&lt;/code&gt;: 由於節點的度數（連接數）可能不同，對聚合的消息進行&lt;code&gt;正規化&lt;/code&gt;有助於防止模型過度依賴於高連接節點，並保證信息流的平衡。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;gnn-在分子建模與藥物發現中的優勢&#34;&gt;GNN 在分子建模與藥物發現中的優勢&lt;/h4&gt;
&lt;p&gt;GNN 的結構化消息傳遞使其能夠有效地從複雜的關係中學習，這在分子和生物應用中尤為重要。主要優勢包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;靈活處理複雜結構: GNN 能夠處理分子圖的不規則和非歐幾里得結構，其中原子和鍵並不遵循網格狀結構。&lt;/li&gt;
&lt;li&gt;高效利用結構信息: 通過嵌入和消息傳遞，GNN 能夠內在地尊重分子內的空間和化學關係。&lt;/li&gt;
&lt;li&gt;可擴展性: GNN 通過基於鄰域的聚合機制，可以有效處理大型圖形數據，例如虛擬篩選中的分子庫。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;結語&#34;&gt;結語&lt;/h2&gt;
&lt;p&gt;使用 GNN 的輸出需要考慮很多的因素，包括任務的性質、數據的結構，以及圖的大小和多樣性。在這個過程中，從聚合技術到模型類型的每一個選擇，都會影響 GNN 對於進行準確且具普遍性預測的能力。&lt;/p&gt;
&lt;p&gt;通過調整這些步驟，並為每種類型的預測選擇合適的方法，GNN 能夠成為處理複雜數據集的強大工具，特別是在藥物發現、分子建模、社交網絡分析等領域中發揮重要作用。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>計算生物學聊聊：藥物開發的現況與挑戰</title>
      <link>http://localhost:1313/post/compbio_drug/</link>
      <pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/compbio_drug/</guid>
      <description>&lt;h2 id=&#34;quick-look&#34;&gt;Quick look&lt;/h2&gt;
&lt;p&gt;本篇介紹藥物開發的現況，筆記出自於美國麻省理工學院的計算生物學課程MLCB24。
課程影片請看&lt;a href=&#34;https://www.youtube.com/watch?v=m_R_6ItR-qY&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;這裡&lt;/a&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;藥物的定義&#34;&gt;藥物的定義&lt;/h2&gt;
&lt;p&gt;從技術角度來說，藥物被定義為由藥典或藥物配方手冊所認可的物質。它必須符合嚴格的標準，包括其成分、製造過程及純度等方面的要求。詳細的定義包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用途：藥物旨在用於診斷、治療、緩解、治癒或預防疾病。這一用途將它與其他物質或化合物區分開來。&lt;/li&gt;
&lt;li&gt;法規：藥物在法規上與食品和醫療器材分開進行管理。儘管存在像醫療食品這樣專為特定疾病的飲食需求而設計的特殊分類，但這些並未被歸類為藥物。此外，醫療器材雖然對醫療非常重要，但它們遵循獨立的法規。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;藥物主要分為兩大類：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;小分子藥物：這些是&lt;code&gt;化學合成&lt;/code&gt;的化合物，傳統上是製藥研究的重點，通常以&lt;code&gt;口服&lt;/code&gt;或注射形式服用。&lt;/li&gt;
&lt;li&gt;生物製劑：這些是由&lt;code&gt;活細胞&lt;/code&gt;或&lt;code&gt;生物體生產&lt;/code&gt;的較大且更複雜的分子，包括抗體、疫苗和基因療法。生物製劑通常需要更複雜的製造過程及保存系統。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;藥物在人類歷史中的角色&#34;&gt;藥物在人類歷史中的角色&lt;/h2&gt;
&lt;p&gt;藥物的使用與發展深深植根於人類歷史，幾乎每個文化都探索過藥用物質。從歷史上看，早期的藥物發現通常來自於大自然，尤其是植物，並受到傳統知識的傳承。以下是一些常見起源於古代的藥物：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;罌粟萃取物&lt;/code&gt;：歷史上用於止痛，罌粟萃取物促成了鴉片類藥物（例如嗎啡和可待因）的發現，這些藥物至今仍是疼痛管理的重要工具。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;柳樹皮&lt;/code&gt;：傳統上用於退燒，後來從中分離出水楊酸，成為阿司匹靈的基礎——這是最廣泛使用的抗炎和止痛藥之一。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;青蒿（Artemisia，甜艾草）&lt;/code&gt;：在中國醫學中被用於治療發燒，後來提供了強效抗瘧藥物青蒿素。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些例子說明了天然產物如何成為藥物發現的起點，而這一趨勢至今仍在持續。然而，現代的藥物開發方式已經大大進化，呈現出更加複雜的科學、法規和技術框架。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;現代藥物發現的框架&#34;&gt;現代藥物發現的框架&lt;/h2&gt;
&lt;p&gt;現代藥物發現的框架是一個&lt;code&gt;結構化&lt;/code&gt;、&lt;code&gt;目標導向&lt;/code&gt;且&lt;code&gt;跨學科&lt;/code&gt;的過程，其目的是將最初的科學研究轉化為具有商業價值的藥物。與傳統依賴運氣或簡單試錯的方法不同，現代藥物發現基於對分子途徑、疾病機制和目標治療設計的深入理解。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;從基礎科學到藥物治療&#34;&gt;從基礎科學到藥物治療&lt;/h2&gt;
&lt;p&gt;藥物發現的過程始於對疾病相關分子途徑的科學研究。研究人員會找出疾病的靶點——一個對疾病病理至關重要的蛋白質、基因或細胞機制。通過理解這些靶點如何運作，他們可以有針對性地尋找能與靶點相互作用的治療劑，藉此改變或抑制其功能以產生有益效果。這些治療劑可以是小分子、生物製劑（如抗體）甚至是具有生物活性的天然產物。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;藥物發現的跨學科性&#34;&gt;藥物發現的跨學科性&lt;/h2&gt;
&lt;p&gt;這個過程極具跨學科特性，需要以下專家的貢獻：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;生物學家和化學家&lt;/code&gt;：理解疾病機制並設計具有預期特性的分子。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;工程師與生物資訊學專家&lt;/code&gt;：優化配送系統和預測藥物行為的計算模型。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;計算生物學家&lt;/code&gt;：利用生物資訊工具分析複雜的生物數據，選擇有潛力的靶點並研究分子間的相互作用。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;商業與法務專家&lt;/code&gt;：確保過程符合法規標準並具有商業價值，處理知識產權（IP）與市場策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;現代藥物發現的協作特性需要數以千計的人員參與，並可能為單一藥物耗資超過10億美元。這種高成本部分源於像美國食品藥品監督管理局（FDA）等法規機構制定的嚴格標準，這些標準要求提供藥物有效性與安全性的證據。雖然這些標準保護患者安全，但同時大幅增加了開發過程的時間、複雜性及成本。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;商業模式在藥物開發中的角色&#34;&gt;商業模式在藥物開發中的角色&lt;/h2&gt;
&lt;p&gt;製藥公司之所以願意投入藥物開發，是因為專利藥物的&lt;code&gt;高利潤&lt;/code&gt;。然而，這種激勵旨在推動創新，但有時可能與治療需求相衝突。理想情況下，治療需求與市場激勵是一致的；然而，特別是在商業模式無法支持低市場吸引力領域的開發時，這種一致性並非總是存在。&lt;/p&gt;
&lt;p&gt;例如，&lt;code&gt;抗生素&lt;/code&gt;的開發便是一個獨特的案例。隨著抗生素耐藥性的增加，對新型抗生素的需求也愈發迫切，但開發它們的商業激勵卻非常薄弱。如果一家製藥公司開發了一種新抗生素，可以有效對抗耐藥細菌，最佳的使用策略可能是限制其在醫院或是社區的使用，以保持其效力並減少耐藥性的產生。然而，有限的使用會降低銷售量，使這種產品的利潤遠低於需要定期、長期使用的藥物。結果，儘管抗生素對全球健康至關重要，但過去幾十年裡新抗生素的投資卻很少。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;調整商業與治療需求的新模式&#34;&gt;調整商業與治療需求的新模式&lt;/h2&gt;
&lt;p&gt;針對像抗生素這樣的案例，商業模式與公共衛生需求之間的不匹配促使研究人員和政策制定者探索替代模式，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;政府資金和補貼&lt;/code&gt;：用於分攤開發成本並鼓勵對低市場回報領域的研究。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;訂閱模式&lt;/code&gt;：醫療系統支付固定金額以獲取抗生素，而不取決於其實際使用頻率，這樣可以讓公司有動機投資抗生素開發。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;專利延長與市場專有權（exclusivity）&lt;/code&gt;：提供更長的專有權，以增加投資回報的可能性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;現代藥物發現框架因此不僅是一個科學和技術的工程，也是一個法規和經濟的挑戰。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;藥物的類型&#34;&gt;藥物的類型&lt;/h2&gt;
&lt;p&gt;在現代醫學中，藥物可以大致分為小分子藥物和生物製劑兩大類，每種類型都有獨特的特性、製造需求和法規途徑。除此之外，還有一些創新的藥物類別，例如活性生物治療劑與細胞療法，這些類別代表了治療開發的新前沿。&lt;/p&gt;
&lt;h3 id=&#34;小分子藥物&#34;&gt;小分子藥物&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;小分子藥物&lt;/code&gt;是低分子量化合物（通常小於900 daltons），一般通過化學合成製備。這些藥物常從天然來源中提取的化合物進行優化，其分子小的特性使它們可以&lt;code&gt;穿透細胞膜&lt;/code&gt;，有效針對細胞內的蛋白質目標。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;合成方式&lt;/code&gt;：通常為化學合成，初期可能基於天然產物的結構改造。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;給藥方式&lt;/code&gt;：多為口服，但有時會使用局部塗抹或注射方式。
例子：阿司匹靈（aspirin）、二甲雙胍（metformin）及他汀類藥物（statins）。
生物製劑&lt;/li&gt;
&lt;li&gt;優點：口服、製備與分配簡易、製造成本較低。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;生物製劑&#34;&gt;生物製劑&lt;/h3&gt;
&lt;p&gt;生物製劑是一類由生物來源衍生的藥物，通常包括&lt;code&gt;較大的分子結構&lt;/code&gt;，如&lt;code&gt;蛋白質、抗體和其他細胞產品&lt;/code&gt;。與小分子藥物不同，生物製劑通常需要注射或靜脈輸液方式給藥，因為其&lt;code&gt;複雜結構會在消化系統中分解&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;例子：乳癌治療藥物Herceptin和糖尿病用胰島素。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;優點：高度專一性，off target 毒性較小。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;活性生物治療劑&#34;&gt;活性生物治療劑&lt;/h3&gt;
&lt;p&gt;活性生物治療劑是使用&lt;code&gt;活微生物（如益生菌）&lt;/code&gt;作為治療劑，旨在利用有益菌調節健康。例如，某些健康個體腸道中的特定細菌可能在某些疾病患者中缺乏，恢復這些細菌可能具有治療效果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;優點：毒性小、效果持久（如果細菌建立了穩定的菌落）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;細胞療法&#34;&gt;細胞療法&lt;/h3&gt;
&lt;p&gt;細胞療法使用活細胞（通常是患者或捐贈者的細胞）來治療疾病，例如CAR-T細胞療法用於癌症治療，幹細胞療法則用於組織再生。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;藥物動力學pharmacokinetics-pk人體如何處理藥物&#34;&gt;藥物動力學（Pharmacokinetics, PK）：人體如何處理藥物&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;藥物動力學&lt;/code&gt;是藥物開發中的核心概念，研究藥物&lt;code&gt;進入人體後的作用過程&lt;/code&gt;。相對地，&lt;code&gt;藥效學（Pharmacodynamics, PD）&lt;/code&gt;則專注於藥物&lt;code&gt;對人體的作用&lt;/code&gt;。藥物動力學對於劑量設計、給藥方式、生物利用度和潛在副作用的評估非常重要。PK研究主要涉及四個階段：吸收、分布、代謝和排泄（縮寫：ADME）。&lt;/p&gt;
&lt;h3 id=&#34;吸收absorption&#34;&gt;吸收（Absorption）&lt;/h3&gt;
&lt;p&gt;吸收是藥物進入血液或作用部位的過程。影響吸收的因素包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;給藥途徑&lt;/code&gt;：例如口服、靜脈注射或吸入。某些途徑能更快或更直接地實現吸收。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;藥物的化學特性&lt;/code&gt;：如親水性（溶於水）或疏水性（溶於脂肪）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;環境條件&lt;/code&gt;：例如吸收部位的血流量與pH值，這些因素會增強或抑制藥物穿越細胞膜的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;藥物的吸收效率決定了其生物利用度（bioavailability），即進入系統循環且以活性形式存在的藥物比例。&lt;/p&gt;
&lt;h3 id=&#34;分布-distribution&#34;&gt;分布 (Distribution)&lt;/h3&gt;
&lt;p&gt;分布是指藥物從血液移動到身體不同組織的過程。關鍵考量包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;血流量&lt;/code&gt;：高血流量的器官（如心臟和肝臟）通常更快接收藥物。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;蛋白質結合&lt;/code&gt;：藥物可能與血液中的血漿蛋白結合，從而&lt;code&gt;限制&lt;/code&gt;了可自由發揮療效的藥物量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;跨越選擇性屏障的能力&lt;/code&gt;：例如&lt;code&gt;血腦屏障（BBB）&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;分布的一個關鍵指標是&lt;code&gt;分布容積（Vd）&lt;/code&gt;，它反映了藥物在身體中相對於血液中濃度的分散程度。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;血腦屏障&lt;/code&gt;是分隔血液與大腦細胞外液的選擇性半透屏障。這一緊密結合的&lt;code&gt;內皮細胞結構&lt;/code&gt;只允許特定分子通過，從而保護大腦免受潛在有害物質的侵害。然而，對於治療中樞神經系統疾病的藥物，血腦屏障會帶來挑戰：&lt;/p&gt;
&lt;p&gt;大分子或親水性分子難以穿透血腦屏障。
解決策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;設計具有更高血腦屏障穿透性的藥物。&lt;/li&gt;
&lt;li&gt;使用奈米粒子傳輸系統幫助藥物穿越屏障。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;鼻腔給藥&lt;/code&gt;：通過鼻腔直接進入神經通路繞過血腦屏障，但是如果想要藥物在腦中有&lt;code&gt;較高&lt;/code&gt;的劑量，這種方式效果較差。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;代謝-metabolism&#34;&gt;代謝 (Metabolism)&lt;/h3&gt;
&lt;p&gt;代謝將藥物轉化為更易於排泄的水溶性形式，主要在肝臟中進行，分為兩個階段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;修飾（Phase I）&lt;/code&gt;：包括酶（如細胞色素P450家族）的氧化或還原作用，使藥物變得更具&lt;code&gt;反應性&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;結合（Phase II）&lt;/code&gt;：增加極性基團（如葡萄糖醛酸化），提升藥物的溶解性，便於排泄。
代謝可能活化藥物、將其轉化為不活躍的代謝產物，或者在某些情況下產生有毒的中間產物。例如，對乙醯氨基酚（acetaminophen）在高劑量下會生成一種&lt;code&gt;有毒中間產物&lt;/code&gt;，可能導致肝損傷。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;排泄-excretion&#34;&gt;排泄 (Excretion)&lt;/h3&gt;
&lt;p&gt;排泄是將藥物及其代謝物從體內移除的過程。常見途徑包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;腎臟（尿液）&lt;/code&gt;：最常見的排泄方式，處理水溶性代謝物。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;肝臟（膽汁）&lt;/code&gt;：某些代謝物通過膽汁分泌，最終經糞便排泄。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;其他途徑&lt;/code&gt;：如汗液、呼吸和母乳，但這些途徑的貢獻較小。
排泄的效率影響藥物的半衰期（half-life），這對於確定給藥頻率以維持治療濃度且不引起毒性非常重要 (圖一)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-圖一&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig1&#34; srcset=&#34;
               /post/compbio_drug/fig1_hu14414697526844801796.webp 400w,
               /post/compbio_drug/fig1_hu5525642444733473667.webp 760w,
               /post/compbio_drug/fig1_hu11859840641213679159.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/compbio_drug/fig1_hu14414697526844801796.webp&#34;
               width=&#34;760&#34;
               height=&#34;499&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖一
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;modelling-of-pk&#34;&gt;Modelling of PK&lt;/h3&gt;
&lt;p&gt;有兩種方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;One component model&lt;/code&gt;：假設人體是一個單一的均勻區室，藥物在進入人體後立即均勻分布整個區室，並隨時間經由代謝或排泄而逐漸被清除。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Two component model&lt;/code&gt;：描述藥物在體內分佈（Distribution phase）與排除（Elimination phase）的過程，分成中央區室與周邊區室，比單一區室的模型更為準確。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;藥效學pharmacodynamics-pd藥物對人體的作用&#34;&gt;藥效學（Pharmacodynamics, PD）：藥物對人體的作用&lt;/h2&gt;
&lt;p&gt;藥效學研究藥物如何與受體、酶或其他細胞靶點作用以產生生物學反應，重點包括藥物作用機制、劑量-反應關係以及治療效果與毒性效應的區分。深入了解藥效學有助於設計療效最大化、副作用最小化的藥物。&lt;/p&gt;
&lt;h3 id=&#34;藥物與受體的相互作用&#34;&gt;藥物與受體的相互作用&lt;/h3&gt;
&lt;p&gt;大多數小分子藥物通過與特定受體（通常是細胞信號通路或酶作用相關的蛋白質）結合來發揮作用。主要的交互方式包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;活化劑（Agonists&lt;/code&gt;）：活化目標受體以產生生物反應。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;拮抗劑（Antagonists）&lt;/code&gt;：與受體結合但阻止其活化，有效抑制反應。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;部分活化劑（Partial Agonists）&lt;/code&gt;：與受體結合並活化受體，但反應較全活化劑弱。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;親和力與效價&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;親和力（Affinity）&lt;/code&gt;：描述藥物與受體的結合強度。高親和力的藥物更容易結合，且效果更持久。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;效價（Potency）&lt;/code&gt;：通常用半最大有效濃度（EC50）衡量，即藥物達到50%最大效果所需的濃度。&lt;/li&gt;
&lt;li&gt;劑量-反應關係&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;劑量-反應曲線顯示藥物劑量與生物效應的關係。關鍵指標包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;最大效應（Emax）&lt;/code&gt;：藥物能產生的最大效果，無關劑量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;藥效（Efficacy）&lt;/code&gt;：藥物能達到的藥效，在合理劑量內。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;治療窗（Therapeutic Window）&lt;/code&gt;：能夠產生治療效果而不引起毒性的劑量範圍。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;藥物毒理學toxicology評估藥物的安全性與副作用&#34;&gt;藥物毒理學（Toxicology）：評估藥物的安全性與副作用&lt;/h2&gt;
&lt;p&gt;毒理學是研究藥物潛在不良反應的學科，在藥物被批准使用之前，確保其安全性是非常重要的。這一領域評估藥物在各種系統與情境下中毒的風險，確保藥物在達成治療目標的同時，不會對健康造成不可接受的影響。&lt;/p&gt;
&lt;p&gt;毒理學研究涵蓋藥物安全性的多個面向，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;急性毒性&lt;/code&gt;：觀察藥物給藥後的即時反應，幫助識別早期副作用或毒性反應。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DNA損傷&lt;/code&gt;：測試藥物是否會導致基因毒性效應，如突變或致癌風險。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;生殖健康&lt;/code&gt;：評估藥物對生育能力、胎兒發育及後代健康的影響，這對於針對育齡人群的藥物尤為重要。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;致癌性&lt;/code&gt;：研究長期暴露於藥物是否會增加癌症風險。這類研究通常耗時且成本高，需進行長期觀察。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，還會針對特定器官進行毒性研究，例如中樞神經系統、呼吸系統和心血管系統。這些研究通常在動物模型中進行，以確保在人類試驗之前，不會出現嚴重器官損害。&lt;/p&gt;
&lt;h3 id=&#34;治療指數therapeutic-index-ti與其重要性&#34;&gt;治療指數（Therapeutic Index, TI）與其重要性&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;治療指數（TI&lt;/code&gt;）是衡量藥物安全性的重要指標，反映藥物的有效劑量與毒性劑量之間的差距：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
TI = TD50/ED50
$$
&lt;/div&gt;
TD50: 導致一半群體產生毒性的劑量。
ED50: 一半群體產生治療效果的劑量。
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;高TI&lt;/code&gt;：顯示有效劑量與毒性劑量之間有較大空間，使用起來更&lt;code&gt;安全&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;低TI&lt;/code&gt;：表示有效劑量與毒性劑量相距較近，用藥時需要更加謹慎。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如，抗凝血藥物華法林（warfarin）具有窄治療指數（narrow TI）。劑量過低無法有效防止血栓，劑量過高則可能導致危險的出血。此外，腸道菌群對華法林的代謝因人而異，進一步增加了劑量調整的挑戰。&lt;/p&gt;
&lt;h3 id=&#34;藥物交互作用&#34;&gt;藥物交互作用&lt;/h3&gt;
&lt;p&gt;藥物可能通過以下方式相互作用，增強或減弱其作用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;協同作用（Synergistic Interactions）&lt;/code&gt;：兩種藥物的聯合作用超過單獨使用的總和。例如，酒精與鎮靜劑都會抑制中樞神經系統，聯合使用可能導致危險的過度鎮靜效應。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;拮抗作用（Antagonistic Interactions）&lt;/code&gt;：一種藥物可能阻斷或抵消另一種藥物的作用。例如，納洛酮（naloxone）通過與鴉片受體結合阻止鴉片類藥物的作用，因此被用作鴉片過量的解毒劑。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;加和效應（Additive Effects）&lt;/code&gt;：某些藥物的聯合作用僅是其單獨作用的總和。例如，降壓藥聯合使用可能更有效地降低血壓，但需謹慎避免過度降壓。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;藥物開發的步驟&#34;&gt;藥物開發的步驟&lt;/h2&gt;
&lt;p&gt;藥物開發是一個高度結構化、多階段的過程，從針對疾病的初步構想到可上市的藥物，期間經歷了大量科學驗證、候選化合物的優化及安全性和有效性的廣泛測試。以下是這一過程的主要階段：&lt;/p&gt;
&lt;h3 id=&#34;靶點識別target-identification&#34;&gt;靶點識別（Target Identification）&lt;/h3&gt;
&lt;p&gt;第一步是識別一個靶點——通常是一個與疾病機制密切相關的蛋白質或基因。靶點選擇基於&lt;code&gt;生物資訊學&lt;/code&gt;、&lt;code&gt;基因組學&lt;/code&gt;和&lt;code&gt;蛋白質組學&lt;/code&gt;，並常使用高通量篩選技術或生物資訊工具。關鍵考量包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;與疾病的關聯性&lt;/code&gt;：該靶點在疾病中有多重要？&lt;/li&gt;
&lt;li&gt;&lt;code&gt;可藥性（Druggability&lt;/code&gt;）：小分子或生物製劑是否能有效地與該靶點結合？&lt;/li&gt;
&lt;li&gt;&lt;code&gt;結構可用性&lt;/code&gt;：是否存在靶點的結構數據或預測（如使用AlphaFold）來指導分子結合設計？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;靶點通常包括酶、受體或疾病機制中關鍵的信號蛋白。然而，一些靶點可能具有挑戰性，例如&lt;code&gt;無穩定結合位點的無序蛋白&lt;/code&gt;或&lt;code&gt;大的平面結構的轉錄因子&lt;/code&gt;。這種情況下，可以考慮生物製劑（單株抗體）或是基因治療（利用CRISPR）。&lt;/p&gt;
&lt;h3 id=&#34;靶點驗證target-validation&#34;&gt;靶點驗證（Target Validation）&lt;/h3&gt;
&lt;p&gt;在靶點識別之後，靶點驗證旨在確認其在疾病中真的具有療效。常見的驗證技術包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CRISPR篩選&lt;/code&gt;與基因過表達研究：操控基因活性並觀察結果。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;動物模型&lt;/code&gt;：模擬疾病狀態。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;生物標誌物分析&lt;/code&gt;：在人類樣本中驗證疾病相關性，提供早期治療效果的線索。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;靶點驗證對於確認調節該靶點是否能帶來治療效果非常重要，避免將無效或無關的靶點列為研究對象。&lt;/p&gt;
&lt;h3 id=&#34;命中化合物識別hit-identification&#34;&gt;命中化合物識別（Hit Identification）&lt;/h3&gt;
&lt;p&gt;在確認靶點後，下一步是識別與靶點相互作用的潛在化合物（hits）。方法包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;高通量篩選（HTS）&lt;/code&gt;：使用&lt;code&gt;生化&lt;/code&gt;或&lt;code&gt;細胞篩選&lt;/code&gt;方法對大量化學庫進行篩選以找到初步活性化合物。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;片段篩選&lt;/code&gt;：使用&lt;code&gt;較小的化學片段 (fragment-based)&lt;/code&gt;結合靶點，然後擴展為更有效的化合物。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;虛擬篩選&lt;/code&gt;：使用計算方法基於靶點結構預測化合物的結合能力，利用&lt;code&gt;分子對接&lt;/code&gt;與&lt;code&gt;機器學習技術&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;命中化合物識別是一個篩選過程，通常從數百萬個化合物中選出少量具有良好結合特性的化合物。&lt;/p&gt;
&lt;h3 id=&#34;命中到先導優化hit-to-lead-optimization&#34;&gt;命中到先導優化（Hit-to-Lead Optimization）&lt;/h3&gt;
&lt;p&gt;選定命中化合物後，進一步優化其結構並研究結構活性關係（&lt;code&gt;structure-activity relationship, SAR）&lt;/code&gt;，以提升結合親和力、特異性和藥物動力學特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;對化學結構進行迭代修改&lt;/code&gt;，提升療效、減少脫靶效應，並改進穩定性和溶解度。一些方式包含：fuctional group modification、chain length alteration、ring modification、isosteric replacement、QSAR等。&lt;/li&gt;
&lt;li&gt;初步進行藥物動力學評估（如吸收、分布、代謝、排泄）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這一步驟旨在將具有潛力的命中化合物轉化為先導化合物，為後續深入研究做好準備。&lt;/p&gt;
&lt;h3 id=&#34;先導化合物優化lead-optimization&#34;&gt;先導化合物優化（Lead Optimization）&lt;/h3&gt;
&lt;p&gt;在這一階段，對先導化合物進行深入的化學與生物物理研究，進一步優化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;提升結合親和力&lt;/code&gt;：提高藥效。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;減少脫靶效應&lt;/code&gt;：降低毒性風險。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;優化藥物動力學特性&lt;/code&gt;：改進半衰期與生物利用度。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;在疾病模型中的療效&lt;/code&gt;：確保早期測試中的療效在更複雜的模型中同樣適用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最終選出的候選化合物將平衡治療效力與安全性，為臨床前與臨床研究鋪平道路。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;藥物開發的時間線&#34;&gt;藥物開發的時間線&lt;/h2&gt;
&lt;p&gt;藥物開發時間線漫長且嚴格，反映出高標準要求以確保療效與安全性。從初始的藥物發現到獲批上市，這一過程通常耗時數十年，涵蓋多個階段，每個階段都面臨顯著挑戰與法規的監督。&lt;/p&gt;
&lt;h3 id=&#34;藥物發現階段&#34;&gt;藥物發現階段&lt;/h3&gt;
&lt;p&gt;這一階段可能耗時數年甚至數十年，包括靶點識別、命中化合物發現及先導化合物的早期優化。
許多初始候選化合物因缺乏療效或安全性問題而被淘汰，只有少數進入下一階段。&lt;/p&gt;
&lt;h3 id=&#34;臨床前測試&#34;&gt;臨床前測試&lt;/h3&gt;
&lt;p&gt;一旦確定了有潛力的先導化合物，便進行臨床前測試，主要在細胞培養和動物模型中進行。
這一階段評估藥物的基礎療效、毒性、藥物動力學和藥效學。
研究結果用於支持提交給FDA的新藥臨床試驗申請（IND）。&lt;/p&gt;
&lt;h3 id=&#34;ind申請&#34;&gt;IND申請&lt;/h3&gt;
&lt;p&gt;提交IND申請是臨床試驗開始前的關鍵步驟。該申請包含安全性數據、製造信息以及擬定的臨床試驗計劃。
如果FDA在指定時間內無異議，藥物開發方即可進行I期臨床試驗。&lt;/p&gt;
&lt;h3 id=&#34;臨床試驗階段&#34;&gt;臨床試驗階段&lt;/h3&gt;
&lt;p&gt;臨床試驗分為三個主要階段，每個階段回答關於藥物的特定問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;I期&lt;/code&gt;：安全性與劑量~在20-80名健康志願者或患者中進行，主要評估&lt;code&gt;安全性&lt;/code&gt;並確定&lt;code&gt;適當的劑量範圍&lt;/code&gt;。目標是建立初步的PK/PD特性，並找出潛在&lt;code&gt;副作用&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;II期&lt;/code&gt;：療效與副作用~包括數十到數百名患有目標疾病的患者。著重於&lt;code&gt;劑量方案的優化&lt;/code&gt;，並&lt;code&gt;檢測早期療效&lt;/code&gt;。該階段為決定&lt;code&gt;是否進一步投入昂貴的III期試驗&lt;/code&gt;提供關鍵數據。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;III期&lt;/code&gt;：大規模測試~涉及&lt;code&gt;數百到數千名患者&lt;/code&gt;，提供獲得法規批准所需的全面數據。該階段&lt;code&gt;確認療效&lt;/code&gt;，監測副作用，並收集患者群體的綜合安全數據。&lt;/li&gt;
&lt;li&gt;上市後監測（IV期）~獲批後的IV期研究或上市後監測，持續觀察藥物在普通人群中的表現。此階段評估長期安全性，可能揭示在臨床試驗中未觀察到的罕見副作用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;成功率與淘汰率&#34;&gt;成功率與淘汰率&lt;/h3&gt;
&lt;p&gt;整個過程中藥物的淘汰率極高，進入臨床試驗的藥物中僅約14%得以批准上市。例如，&lt;code&gt;癌症藥物的成功率更低&lt;/code&gt;，從I期至上市的成功率僅約&lt;code&gt;3%&lt;/code&gt;（圖二）。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-圖二-第二期試驗的成功率最低&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig2&#34; srcset=&#34;
               /post/compbio_drug/fig2_hu16441939913604798509.webp 400w,
               /post/compbio_drug/fig2_hu890291919401304658.webp 760w,
               /post/compbio_drug/fig2_hu14679296414677028875.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/compbio_drug/fig2_hu16441939913604798509.webp&#34;
               width=&#34;644&#34;
               height=&#34;636&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖二 第二期試驗的成功率最低
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;財務影響&#34;&gt;財務影響&lt;/h3&gt;
&lt;p&gt;藥物開發成本極高，單一藥物平均耗資約10億美元。成本涵蓋了成功藥物與失敗試驗的總和，FDA批准過程本身也涉及高昂的行業費用，例如IND和新藥申請（NDA）的提交費用。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;結論&#34;&gt;結論&lt;/h2&gt;
&lt;p&gt;藥物開發是一個複雜、多階段的過程，需耗費大量時間、資源與法規合規性。這一漫長的時間線和高淘汰率凸顯了開發安全有效藥物的困難與昂貴，強調了精準與創新的重要性。未來，我們將進一步探索現代計算技術如何縮短藥物開發時間線，提高成功率並降低總成本。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>計算生物學聊聊：Hidden Markov Chain (上)</title>
      <link>http://localhost:1313/post/markov1/</link>
      <pubDate>Mon, 09 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/markov1/</guid>
      <description>&lt;h2 id=&#34;quick-look&#34;&gt;Quick look&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Hidden Markov Chain(HMM)&lt;/code&gt;是計算生物學中一個重要的數學模型，廣泛應用於DNA序列分析和蛋白質結構預測等領域。HMM的核心概念是用&lt;code&gt;隱藏的狀態&lt;/code&gt;來建立模型，並解釋觀察到的數據，通過&lt;code&gt;轉移機率&lt;/code&gt;和&lt;code&gt;觀察機率&lt;/code&gt;來描述系統的動態行為。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;markov-chain&#34;&gt;Markov chain&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Markov chain&lt;/code&gt;是一種數學模型，用於描述一個系統在&lt;code&gt;離散&lt;/code&gt;時間內的&lt;code&gt;狀態轉移過程&lt;/code&gt;。它的核心特點是 &lt;code&gt;&amp;quot;無記憶性&amp;quot;&lt;/code&gt;，即下一個狀態&lt;code&gt;僅取決於當前狀態&lt;/code&gt;，而與過去的狀態無關。&lt;/p&gt;
&lt;h2 id=&#34;基本定義&#34;&gt;基本定義&lt;/h2&gt;
&lt;p&gt;Markov chain 的所有可能狀態的集合，通常表示為：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
S={s1​,s2​,…,sn​}
$$
&lt;/div&gt;
&lt;h2 id=&#34;轉移概率transition-probability&#34;&gt;轉移概率（Transition Probability）&lt;/h2&gt;
&lt;p&gt;從當前狀態&lt;em&gt;Si&lt;/em&gt; 到下一個狀態&lt;em&gt;Sj&lt;/em&gt;，記為&lt;em&gt;Pij&lt;/em&gt;:&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
Pij=P(Xt+1​=Sj​∣Xt​=Si​)
$$
&lt;/div&gt;
&lt;p&gt;其中，&lt;em&gt;Xt&lt;/em&gt; 表示時間&lt;em&gt;t&lt;/em&gt; 時系統的狀態&lt;/p&gt;
&lt;h2 id=&#34;轉移矩陣transition-matrix&#34;&gt;轉移矩陣（Transition Matrix）&lt;/h2&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
P = 
\begin{bmatrix}
P_{11} &amp; P_{12} &amp; \ldots &amp; P_{1n} \\
P_{21} &amp; P_{22} &amp; \ldots &amp; P_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
P_{n1} &amp; P_{n2} &amp; \ldots &amp; P_{nn}
\end{bmatrix}
$$
&lt;/div&gt;
&lt;p&gt;&lt;code&gt;每一列的概率總和為 1&lt;/code&gt;：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
\sum_{j}Pij​=1
$$
&lt;/div&gt;
&lt;h2 id=&#34;初始分佈initial-distribution&#34;&gt;初始分佈（Initial Distribution）&lt;/h2&gt;
&lt;p&gt;系統初始時處於每個狀態的概率，記為向量 π:&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
π=[π_1​,π_2​,…,π_n​],\sum_{i=1}π_i​=1
$$
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;markov-chain的性質&#34;&gt;Markov chain的性質&lt;/h2&gt;
&lt;h2 id=&#34;無記憶性markov-property&#34;&gt;無記憶性（Markov Property）&lt;/h2&gt;
&lt;p&gt;下一狀態的分佈僅取決於當前狀態：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
P(Xt+1​=Sj​∣Xt​=Si​,Xt−1​,…,X1​)=P(Xt+1​=Sj​∣Xt​=Si​)
$$
&lt;/div&gt;
&lt;h2 id=&#34;穩態分佈stationary-distribution&#34;&gt;穩態分佈（Stationary Distribution）&lt;/h2&gt;
&lt;p&gt;當Markov chain運行足夠長時間後，系統的狀態分佈趨於穩定，滿足：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
π = πP
$$
&lt;/div&gt;
&lt;hr&gt;
&lt;h2 id=&#34;markov-chain-實例&#34;&gt;Markov chain 實例&lt;/h2&gt;
&lt;p&gt;假設我們有一個系統，代表每天的天氣狀態，狀態空間為：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
S = [晴天, 雨天]
$$
&lt;/div&gt;
&lt;p&gt;轉移概率如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;晴天後下一天仍是晴天的概率為 0.8; 變為雨天的概率為
0.2。&lt;/li&gt;
&lt;li&gt;雨天後下一天變為晴天的概率為 0.6，仍是雨天的概率為 0.4。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;轉移矩陣可以表示為：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
P = 
\begin{bmatrix}
0.8 &amp; 0.2 \\
0.6 &amp; 0.4
\end{bmatrix}
$$
&lt;/div&gt;
&lt;p&gt;初始分佈：&lt;/p&gt;
&lt;p&gt;假設第一天是晴天：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
π=[1,0]
$$
&lt;/div&gt;
運行Markov chain可以計算未來任一天的天氣分佈。
&lt;hr&gt;
&lt;h2 id=&#34;hmm&#34;&gt;HMM&lt;/h2&gt;
&lt;p&gt;HMM常用於分析序列數據或時序數據，尤其是當觀察數據（顯性數據）與內部狀態（隱藏狀態）之間存在間接關係時。HMM 是一種生成式模型 (generative model)，通過隱藏狀態的轉移和觀察狀態的生成來描述數據行為。&lt;/p&gt;
&lt;p&gt;類似於Markov chain，HMM除了有觀察狀態之外，還包含了隱藏狀態 (hidden state)，隱藏狀態是一組未直接觀察到的狀態，用來描述系統的內部狀態。如投擲硬幣時，我們只會&lt;code&gt;觀察&lt;/code&gt;到正面和反面，但是硬幣是真硬幣還是假硬幣是被隱藏起來的，而隱藏狀態之間的轉移由&lt;code&gt;轉移機率&lt;/code&gt;矩陣來描述。而隱藏狀態生成觀察狀態的機率用觀察機率矩陣 (emission probability matrix) 來描述：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
B={b_jk​},b_jk​=P(ok​∣Sj​)
$$
&lt;/div&gt;
&lt;h2 id=&#34;hmm-性質&#34;&gt;HMM 性質&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;隱藏狀態與觀察數據的關係
隱藏狀態 &lt;em&gt;S&lt;/em&gt; 影響觀察數據 &lt;em&gt;O&lt;/em&gt;，但隱藏狀態本身無法直接觀測。
每一個觀察 &lt;em&gt;Ot&lt;/em&gt; 僅與當前隱藏狀態 &lt;em&gt;St&lt;/em&gt; 相關。&lt;/li&gt;
&lt;li&gt;隱藏狀態之間的轉移滿足Markov chain property，未來的狀態僅依賴&lt;code&gt;當前&lt;/code&gt;狀態，與過去狀態無關。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;範例&#34;&gt;範例&lt;/h2&gt;
&lt;p&gt;接下來我來看一個簡單的例子：
















&lt;figure  id=&#34;figure-圖一&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig1&#34; srcset=&#34;
               /post/markov1/fig1_hu8822840645180452515.webp 400w,
               /post/markov1/fig1_hu2316656150060041621.webp 760w,
               /post/markov1/fig1_hu8691795879731039526.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/markov1/fig1_hu8822840645180452515.webp&#34;
               width=&#34;760&#34;
               height=&#34;348&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖一
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;這張圖是一個兩狀態HMM，其中隱藏狀態代表&lt;code&gt;公平硬幣&lt;/code&gt;（Fair Coin,
F) 與&lt;code&gt;偏斜硬幣&lt;/code&gt;（Biased Coin, B)，並包含以下數學定義：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始狀態分佈:&lt;/li&gt;
&lt;/ol&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
πF​=0.4,πB​=0.6
$$
&lt;/div&gt;
這表示系統初始時處於公平硬幣狀態的機率為 0.4，而偏斜硬幣狀態的機率為 0.6。
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;轉移機率矩陣 (隱藏狀態的轉移機率):&lt;/li&gt;
&lt;/ol&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
A =
\begin{bmatrix}
P(F \to F) &amp; P(F \to B) \\
P(B \to F) &amp; P(B \to B)
\end{bmatrix}
=
\begin{bmatrix}
0.9 &amp; 0.1 \\
0.3 &amp; 0.7
\end{bmatrix}
$$
&lt;/div&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;觀察機率矩陣:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;每個隱藏狀態對應不同的觀察機率分佈。&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
B =
\begin{bmatrix}
P(H \mid F) &amp; P(T \mid F) \\
P(H \mid B) &amp; P(T \mid B)
\end{bmatrix}
=
\begin{bmatrix}
0.5 &amp; 0.5 \\
0.8 &amp; 0.2
\end{bmatrix}  
$$
&lt;/div&gt;
&lt;p&gt;上面的數學描述基本上告訴我們:&lt;/p&gt;
&lt;p&gt;當處於某一隱藏狀態 &lt;em&gt;St&lt;/em&gt; 時，根據對應的觀察機率矩陣 &lt;em&gt;B&lt;/em&gt; 生成觀察 &lt;em&gt;Ot&lt;/em&gt;。例如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;若 &lt;em&gt;St&lt;/em&gt; = F，則生成 &lt;em&gt;H&lt;/em&gt; 或 &lt;em&gt;T&lt;/em&gt; 的機率皆為0.5。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若 &lt;em&gt;St&lt;/em&gt; = B，則生成 &lt;em&gt;H&lt;/em&gt; 的機率為0.8，生成 &lt;em&gt;T&lt;/em&gt; 的機率為0.2。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;機率計算
對於給定的觀察序列&lt;em&gt;O&lt;/em&gt; = {&lt;em&gt;H&lt;/em&gt;, &lt;em&gt;T&lt;/em&gt;, &lt;em&gt;H&lt;/em&gt;}，我們可以計算總機率：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
P(O∣λ)
$$
&lt;/div&gt;
&lt;p&gt;然而，上面的總機率必須考慮所有&lt;code&gt;隱藏狀態的序列&lt;/code&gt;，即便是 &lt;em&gt;H&lt;/em&gt;，有可能 fair coin或是biased coin擲出，而這兩種狀態都必須考慮進來，然後加總。所以一旦序列很長，計算的&lt;code&gt;複雜度&lt;/code&gt;會變得很大，導致在計算上無法順利執行，為了解決個問題，接下來會介紹一些常見的HMM演算法來解決這個問題。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;forward-procedure&#34;&gt;Forward procedure&lt;/h2&gt;
&lt;p&gt;前向算法&lt;code&gt;（Forward Algorithm）&lt;/code&gt; 是 HMM 中用於計算觀察序列的總機率 P(O∣λ) 的一種高效動態規劃方法。這個機率表示給定模型參數 λ = (F,B,π) 時，生成觀察序列 O= {o1,o2,…,oT} 的機率。
















&lt;figure  id=&#34;figure-圖二&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig2&#34; srcset=&#34;
               /post/markov1/fig2_hu4390774657599844428.webp 400w,
               /post/markov1/fig2_hu9501806590322226021.webp 760w,
               /post/markov1/fig2_hu16811126276551008659.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/markov1/fig2_hu4390774657599844428.webp&#34;
               width=&#34;708&#34;
               height=&#34;408&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖二
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;如圖二所示，我今天要來計算硬幣投擲序列的總機率，對於HMM來說，當下的隱藏態具有Markov chain property，亦即只依賴前一個隱藏態的分佈與轉移。&lt;/p&gt;
&lt;p&gt;當t=1時，我們看到觀測值為 T，而T的出現機率由初始的隱藏狀態F和B來決定，而F與B分別有一個emission probability，表示由隱藏態映射到觀察值的機率，所以如果一開始投擲硬幣時使用到fair coin的機率為0.6，而&lt;code&gt;使用此硬幣&lt;/code&gt;，也就是此&lt;code&gt;狀態&lt;/code&gt;投出 T 的機率為0.5，那麼出現 T 的機率為 α1(F) = 0.6 * 0.5 = 0.3。&lt;/p&gt;
&lt;p&gt;但是這還不夠，因為我們必須要考慮所有可能出現的狀態，因此還要考慮biased coin投擲時的情況，如果在biased coin 投擲下出現 T 機率為0.4 * 0.2 = 0.08， 那麼在 t=1 時出現 T 的機率就等於 α1(B) = 0.3 + 0.08 = 0.38。&lt;/p&gt;
&lt;p&gt;我們可以把兩個隱藏狀態映射出來的機率結果當成一個&lt;code&gt;節點&lt;/code&gt; （圖二中紅色的點），而這個節點儲存了隱藏狀態運算的結果，而我們可以把個運算結果傳到下一個觀察時間點，也就是下一次的投擲。&lt;/p&gt;
&lt;p&gt;而這邊有一個很重要的概念就是，下一個觀察值取決於當下的隱藏狀態，而當下的隱藏狀態取決於前一個隱藏態，而非觀察值的結果，因為觀察值是已知，不像隱藏狀態有機率分佈，在了解了這個區別之後，接下來我們要進行下一次的硬幣投擲。
第二次投擲的結果為H，所以&lt;code&gt;累積到第二次投擲&lt;/code&gt;，O = {&lt;em&gt;T&lt;/em&gt;, &lt;em&gt;H&lt;/em&gt;} 的機率為以下所有情況的加總：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;前一個狀態為 F，這次狀態為 F: α1(F) * αFF * bFH&lt;/li&gt;
&lt;li&gt;前一個狀態為 B，這次狀態為 F: α1(B) * αBF * bFH&lt;/li&gt;
&lt;li&gt;前一個狀態為 F，這次狀態為 B: α1(F) * αFB * bBH&lt;/li&gt;
&lt;li&gt;前一個狀態為 B，這次狀態為 B: α1(B) * αBB * bBH&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;注意α1(F)及α1(B)已經記憶了前一個狀態的結果，所以再往後的運算，更前面的數據結果都可以拋棄，節省記憶體。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上面的過程可以用以下的數學式來描述：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化：
對於時間 t=1：&lt;/li&gt;
&lt;/ol&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
α_1​(i) =π_i​ \cdot b_i​(O_1​),1≤i≤N
$$
&lt;/div&gt;
&lt;p&gt;其中，&lt;em&gt;πi&lt;/em&gt; 是初始狀態分佈，&lt;em&gt;bi(O1)&lt;/em&gt; 是狀態 &lt;em&gt;si&lt;/em&gt; 下產生觀察 &lt;em&gt;O1&lt;/em&gt; 的機率。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;遞推（時間 t&amp;gt;1）:
對於每個時間步t = 2,3,4,5&amp;hellip;T，計算每個隱藏狀態的 αt​(i)：&lt;/li&gt;
&lt;/ol&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
\alpha_t(i) = \left( \sum_{j=1}^N \alpha_{t-1}(j) \cdot a_{ji} \right) \cdot b_i(o_t), \quad 1 \leq i \leq N
$$
&lt;/div&gt;
其中，
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;αt-1(j)&lt;/em&gt;: 表示前一個時刻在狀態 &lt;em&gt;sj&lt;/em&gt; 的機率。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;αji&lt;/em&gt;: 表示從狀態 &lt;em&gt;sj&lt;/em&gt; 轉移到 &lt;em&gt;si&lt;/em&gt; 的機率。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;bi(Ot)&lt;/em&gt;: 表示在狀態 &lt;em&gt;si&lt;/em&gt; 下生成觀察 &lt;em&gt;Ot&lt;/em&gt; 的機率。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;用上面的例子來說明，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;αt-1(j)&lt;/em&gt; 為 α1(F): 表示前一個狀態為fair coin下的機率結果=0.3。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;aji&lt;/em&gt; 為 αFF 及 αBF。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;bi(Ot)&lt;/em&gt; 為 bFH 及 bBH。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;結論&#34;&gt;結論&lt;/h2&gt;
&lt;p&gt;HMM 是在 Markov chain 上的擴展，允許狀態是隱藏的（hidden），而我們只能觀察到通過這些狀態生成的觀察值。它由三個主要部分構成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;隱藏狀態（Hidden States）：如公平硬幣（Fair Coin）或偏斜硬幣（Biased Coin）。&lt;/li&gt;
&lt;li&gt;轉移機率（Transition Probabilities）：描述隱藏狀態之間的轉移。&lt;/li&gt;
&lt;li&gt;觀察機率（Emission Probabilities）：描述隱藏狀態生成觀察值的可能性。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;之後的文章我會探討針對其他演算法及HMM在生物資訊學中的運用。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
