<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DLit-Hub</title>
    <link>http://localhost:1313/</link>
      <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <description>DLit-Hub</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu15379254428347791189.png</url>
      <title>DLit-Hub</title>
      <link>http://localhost:1313/</link>
    </image>
    
    <item>
      <title>纖維母性網狀細胞為肺癌中的T細胞塑造碉堡？</title>
      <link>http://localhost:1313/post/paperr3/</link>
      <pubDate>Wed, 27 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/paperr3/</guid>
      <description>&lt;h2 id=&#34;quick-look&#34;&gt;Quick look&lt;/h2&gt;
&lt;p&gt;腫瘤內部的免疫微環境基本上都存在高度異質性，從免疫細胞密集分布到完全缺乏等等。目前的證據顯示，腫瘤抗原特異性T細胞(Tumor-specific T cell)若要順利的啟動及維持他們的活性，仰賴腫瘤引流淋巴結(tumor draining lymph node)和腫瘤組織內的微環境，特別是三級淋巴結構（tertiary lymphoid structure，TLS），其通常位於腫瘤邊緣並由B細胞主導。而TLS中的B細胞活性也與Immune checkpoint inhibitor的成功率息息相關。&lt;/p&gt;
&lt;p&gt;這些免疫細胞由專門的纖維母細胞(如T細胞區網狀細胞和血管周圍網狀細胞)支撐，而這之間的交互作用也從TLS透過某種物理架構延伸到腫瘤內部。本篇研究通過單細胞轉錄組學和高解析度顯微技術，發現了在肺癌中形成特定T細胞環境的纖維母細胞亞群(fibroblastic reticular cell)。這些FRC與免疫細胞的互動促進了TLS的形成、T細胞軌跡中的分化，以及控制T細胞活性。實驗顯示，破壞腫瘤微環境中FRC與免疫細胞的互動會降低CD8+ T細胞的抗腫瘤活性並促進腫瘤生長。&lt;/p&gt;
&lt;p&gt;由此可見，特定的FRC亞群通過提供增長和分化的信號，在腫瘤內部支持保護性免疫反應(protective immunity)，對抗腫瘤生長。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>基礎模型於醫學領域的運用？</title>
      <link>http://localhost:1313/post/paperr2/</link>
      <pubDate>Mon, 25 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/paperr2/</guid>
      <description>&lt;h2 id=&#34;quick-look&#34;&gt;Quick look&lt;/h2&gt;
&lt;p&gt;人工智慧的快速發展，特別是高靈活性和可重複使用的模型，預計將為醫學領域帶來全新的能力。這篇發表於nature的&lt;a href=&#34;https://www.nature.com/articles/s41586-023-05881-4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;文章&lt;/a&gt;提出了一種新的醫學AI模式，稱為通用型醫學人工智慧(Generalist Medical AI，GMAI)。GMAI 模型將能夠在極少甚至不依賴特定任務標註數據的情況下，執行多樣化的醫學任務。這些模型通過對大規模、多樣性數據集的自監督學習構建，能靈活解讀多種醫學數據模態的組合，包括影像數據、電子健康紀錄(EHR)、實驗室檢驗結果、基因組數據、圖形數據和醫學文本等。GMAI模型的輸出將更具表達性，例如提供自由文本解釋、語音建議或圖像註解，並展現出高級的醫學推理能力。&lt;/p&gt;
&lt;h1 id=&#34;基礎模型真的有那麼強大&#34;&gt;基礎模型真的有那麼強大？&lt;/h1&gt;
&lt;p&gt;基礎模型(Foundation Models)是最新一代的AI模型，基於大規模、多樣化的數據集訓練，並可用於多種下游任務。
與以往專注於單一任務的AI模型不同，基礎模型具備處理多任務的靈活性和通用性，例如回答文本問題、描述圖像以及玩電子遊戲。&lt;/p&gt;
&lt;p&gt;隨著數據集規模的增長、模型規模的增大以及模型架構的改進，基礎模型讓學界看到了AI強大的潛能。最著名的例子為於2020年發表的GPT-3，藉由通過&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;上下文學習&lt;/span&gt;，僅需要提供一些實例或提示(prompts)，就能針對先前&lt;strong&gt;未曾訓練過&lt;/strong&gt;的資料作出判斷。而另一項關於基礎模型的潛能是，這種模型可以同時接受多種類型的數據模態(如圖像、文本)並生成輸出。另如Google DeepMind於2022年發表的Gato&lt;a href=&#34;https://deepmind.google/discover/blog/a-generalist-agent/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;模型&lt;/a&gt;能夠進行聊天、描述圖像、玩電子遊戲及控制機器臂，被視為通用代理(Generalist Agent)。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;還記得2020 GPT-3第一次公開讓使用者使用時，我在醫院和同事都驚呆了，立馬使用這個強大的聊天機器人來優化我們寫的程式代碼。而現在的發展更為進步、套件更為豐富，已經可以很好的輸出程式碼、生成圖片以及閱讀檔案，只能感嘆AI的迅速發展。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;醫學基礎模型的挑戰&#34;&gt;醫學基礎模型的挑戰&lt;/h1&gt;
&lt;p&gt;目前的醫學AI模型仍以特定任務為主，缺乏靈活性和通用性。例如胸部X光判讀模型只能檢測肺炎，無法完成完整的放射學報告。
此類模型高度依賴人工標註的數據集，且模型的應用範圍受限於訓練數據的標記。在FDA批准的超過500款臨床醫學AI模型中，大多僅針對1或2個任務，由此可見光靠一兩個模型無法解決所有臨床上的問題，而匯集所有的模型也顯得曠日廢時，不切實際。探究其受限的原因，實在是因為醫學數據集在獲取上有一定的難度，且數據高度多樣化，針對一個癌症病人，不僅要收集影像數據，還要收集所有的臨床資料、甚至是基因組資料，而每一種資料的格式都不同，可想而知整合的困難度。&lt;/p&gt;
&lt;p&gt;然而，近年基礎模型的發展或許可以顛覆我們對醫學AI的認知。此篇文章的團隊提出GMAI(圖一)，期望這種基礎模型將取代目前的特定任務醫學AI模型，成為通用模型。GMAI具有三大關鍵能力：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;動態任務理解&lt;/strong&gt;：模型只需用簡單的語言描述任務即可執行新問題，&lt;strong&gt;無需重新訓練&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多模態輸入輸出&lt;/strong&gt;：能處理並生成多種數據模態的組合(如影像、文本、實驗室結果等)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;靈活應用於未知問題&lt;/strong&gt;：GMAI能代表醫學知識，解決未曾明確訓練過的新任務。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-圖一&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;GMAI&#34; srcset=&#34;
               /post/paperr2/fig1_hu4465402215046398491.webp 400w,
               /post/paperr2/fig1_hu7223638083453739918.webp 760w,
               /post/paperr2/fig1_hu1798559871620689176.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/paperr2/fig1_hu4465402215046398491.webp&#34;
               width=&#34;760&#34;
               height=&#34;376&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖一
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;目前現況&#34;&gt;目前現況&lt;/h1&gt;
&lt;p&gt;其實有用過ChatGPT的醫師都知道，他已經可以通過醫師國考了，而目前在輸入進去某疾病的特徵也通常可以做簡單的鑑別診斷，甚至做出正確的判斷，這都是仰賴我們不斷地輸入以及反饋，這個GPT模型才能越來越好。然而即便如此，針對非文本型態的醫學資料，GPT顯然無法做多模態的協同處理來生成事實陳述，也無法在用戶端提供靈活的互動，讓醫師能藉由介面操作腫瘤的識別。
而針對多模態，GMAI可以整合使用者的輸入，將輸入轉換成&lt;strong&gt;token&lt;/strong&gt;，每個token都代表模態的一小部分，如一句話中的一個字，或是一張圖片的一個角落，而整合的token將代表使用者的輸入，並且可以再用&lt;strong&gt;transformer&lt;/strong&gt;的模型結構做處理，讓GMAI可以針對不同種類的輸入做理解。&lt;/p&gt;
&lt;h1 id=&#34;醫學知識&#34;&gt;醫學知識&lt;/h1&gt;
&lt;p&gt;傳統醫學AI模型在訓練之前，通常缺乏對醫學領域的背景知識，僅依賴輸入數據與目標預測之間的統計關係。這種缺乏背景知識的特性，使得在數據稀缺時，訓練模型完成特定醫學任務更加困難。而GMAI可以通過結構化的知識圖譜(knowledge graphs)，可以推理醫學概念及其之間的關係。基於最新的&lt;strong&gt;檢索技術(retrieval-based)&lt;/strong&gt;，GMAI能從現有資料庫（如文章、影像或過去案例）中獲取相關背景，提供上下文支持。GMAI也可提供解釋性預警，例如：「該患者可能會發展為急性呼吸窘迫綜合症，因其近期因嚴重胸部創傷住院，且儘管吸入氧氣濃度增加，但動脈血氧分壓仍持續下降。」當需要提供治療建議時，GMAI模型甚至可推斷並利用醫學概念與臨床發現之間的因果關係，這對其在臨床中的應用至關重要。&lt;/p&gt;
&lt;p&gt;最後一個是解決數據稀缺問題，通過豐富的分子與臨床知識，GMAI能將相關問題的知識轉移到目標任務，進而解決數據有限的任務。一個典型例子是AI在藥物重新定位(drug repurposing)中的應用，可以解決在有限藥物數據庫或是交互作用的資料背景下，提供臨床一個新的方案。&lt;/p&gt;
&lt;h1 id=&#34;gmai的終極優勢&#34;&gt;GMAI的終極優勢!?&lt;/h1&gt;
&lt;h2 id=&#34;controllability&#34;&gt;Controllability&lt;/h2&gt;
&lt;p&gt;GMAI允許用戶細緻控制其輸出格式，使得複雜的醫學信息更加易於理解。例如：模型可以根據需求重新表述自然語言原本的回應。
也可以調整視覺化內容(如改變視角或標註重要特徵)。能根據需求調整輸出中的專業細節程度，甚至翻譯為多種語言，方便與不同背景或是語言的醫師交流。用戶也需要接受正式培訓，以學習如何有效的查詢和使用GMAI的輸出。&lt;/p&gt;
&lt;h2 id=&#34;adaptability&#34;&gt;Adaptability&lt;/h2&gt;
&lt;p&gt;傳統醫學AI模型在技術、環境或人口設定的改變下會有表現不佳的狀況，而GMAI能通過「上下文學習」快速適應。
例如，醫院只需提供少量例子作為提示，就能讓GMAI解讀來自新型X光機器的影像，而傳統模型則需在全新數據集上重新訓練。
另一個有用的應用場景如：GMAI能快速適應新冠病毒的變異株，例如在臨床醫師的提示下，可以將「支氣管和血管周圍浸潤」視為指標，作為「Omicron肺炎」的影像特徵依據，並更新對變異株的認識。&lt;/p&gt;
&lt;h2 id=&#34;applicability&#34;&gt;Applicability&lt;/h2&gt;
&lt;p&gt;GPT-3 作為 AI 基礎模型的成功案例，其發布後幾個月內被應用於超過300個應用程式中。另外如&lt;strong&gt;CheXzero&lt;/strong&gt;可以在不依賴標籤的情況下，檢測胸部X光中的數十種疾病。因此，GMAI將驅動大規模醫學AI模型的開發與應用。這些模型既可直接生成輸出供臨床應用，也可生成中間數值表示作為專業子模型的輸入，用於執行特定任務。然而GMAI的靈活性也可能成為一把&lt;strong&gt;雙刃劍&lt;/strong&gt;，若基礎模型中存在缺陷，這些問題可能會在下游應用中被擴大。&lt;/p&gt;
&lt;h1 id=&#34;gmai現階段的挑戰&#34;&gt;GMAI現階段的挑戰&lt;/h1&gt;
&lt;h2 id=&#34;validation&#34;&gt;Validation&lt;/h2&gt;
&lt;p&gt;要驗證GMAI其實非常困難，因為它具有多功能且能執行用戶首次設定的全新任務，難以預測所有可能的錯誤模式。現有AI模型只需針對特定任務進行驗證(如腦部MRI診斷特定癌症)，但GMAI涉及更多不可預見的任務場景，也有辦法診斷所有腦部腫瘤，所以我們無法針對每一種疾病去設計驗證。因此開發者和監管機構需解釋GMAI的測試範圍與用途。界面應設計警示功能，以防在未知場景下生成不準確的訊息。&lt;/p&gt;
&lt;h2 id=&#34;verification&#34;&gt;Verification&lt;/h2&gt;
&lt;p&gt;GMAI 處理的輸入與輸出更為複雜（如結合影像、數據、文本），使其正確性更難由單一專業的醫師來做驗證。與傳統模型相比，GMAI 的輸出可能需要多學科團隊(放射科醫師、病理學家、腫瘤學家等)共同判斷。因此可以引入解釋性技術，例如附上文獻支持的連結，幫助臨床醫師更有效地驗證模型的預測。也要確保模型能準確表達不確定性(&lt;strong&gt;uncertainty&lt;/strong&gt;)，避免生成過度自信的結論。&lt;/p&gt;
&lt;h2 id=&#34;social-bias&#34;&gt;Social bias&lt;/h2&gt;
&lt;p&gt;先前的醫學AI模型已經證實，在訓練中可能因數據集中於某些患者群體，而產生代表性不足的偏見。而GMAI所需的訓練數據規模和複雜性將使這個偏見的問題更為顯著。因此，模型需經過全面驗證，確保在少數族裔或特定群體中的表現也同樣的好。部署後需持續審核和監督，並鼓勵社群通過獎勵競賽找出潛在偏見或錯誤模式。&lt;/p&gt;
&lt;h2 id=&#34;privacy&#34;&gt;Privacy&lt;/h2&gt;
&lt;p&gt;GMAI可能暴露敏感的患者數據，而惡意用戶可能通過提示攻擊(prompt attacks)繞過限制，提取敏感信息。所以開發者應當強化數據匿名化並限制單一患者的數據收集量。&lt;/p&gt;
&lt;h2 id=&#34;scalability&#34;&gt;Scalability&lt;/h2&gt;
&lt;p&gt;GMAI模型的規模和訓練成本驚人，如GPT-3訓練需數百億標記數據，PaLM模型也耗費數百萬美元購買3000-6000 TPU v4處理晶片。訓練大模型對環境也有巨大影響，每個模型可能產生數百噸的二氧化碳當量。這樣的規模，讓我們不禁思考，到底要多大才夠？最近的一項研究建立了數據集大小與模型大小之間的聯繫，建議數據集的token數量應該是模型參數數量的20倍，以達到最佳的性能。然而，現有的基礎模型即使在較低的token數與參數數比值下也能成功訓練。因此，在開發GMAI模型時，仍然難以確定模型和數據集需要多大，特別是因為所需的規模在很大程度上取決於具體的醫學情境。&lt;/p&gt;
&lt;p&gt;GMAI開發需要大規模醫學數據，但與一般基礎模型不同，這些數據需專注於醫學領域，並滿足匿名化和兼容性要求。即便如此，我們依然能利用現有的基礎模型來做前期的訓練，至少會讓GMAI帶有一些基本的功能。最好的例子就是在大量輸入醫學文本進ChatGPT後，ChatGPT就可以回答醫學的問題，甚至通過醫師國考。但我們若是要專注在醫學領域，就必須在取得各部門的同意後集成整合的資料，當這個規模變大的時候，政策以及資料的相容性都會是一大挑戰。有一些方式是該模型的聊天機器人可以集中部署在計算集群上以降低需求，如部署在DALL-E或是GPT-3。但若不是一般的聊天機器人，其他的模型就必須要部署在醫院內部以供醫師隨時運用，這個時候就需要考慮knowledge distillation的技術(&lt;a href=&#34;https://blog.roboflow.com/what-is-knowledge-distillation/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;圖二&lt;/a&gt;)，將大模型壓縮為更小模型，方便本地部署。&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-圖二&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig2&#34; srcset=&#34;
               /post/paperr2/fig2_hu5603937334617053369.webp 400w,
               /post/paperr2/fig2_hu14445273741430393331.webp 760w,
               /post/paperr2/fig2_hu10463116408328140366.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/paperr2/fig2_hu5603937334617053369.webp&#34;
               width=&#34;760&#34;
               height=&#34;340&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖二
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;結論&#34;&gt;結論&lt;/h1&gt;
&lt;p&gt;GMAI將成為醫療革命的催化劑，它就像一位全能的「數位醫生」，能輕鬆解析多種醫療數據，快速學會新任務，適應不同場景，不論是在傳統診室中輔助醫生診斷，還是在偏遠地區的智能設備上提供健康指導。它不僅能幫助醫生減輕繁瑣的文書負擔，讓他們有更多時間專注於患者，還能打破地域與語言的限制，讓高品質的醫療普及到每一個角落。然而，這樣的「超級醫生」也面臨隱私保護、數據收集和高計算成本等挑戰，但只要跨越這些障礙，GMAI將徹底改變我們看待和實現醫療的方式，讓醫療更有效率與更人性化。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>數據科學技術盤點:主成分分析？</title>
      <link>http://localhost:1313/post/data_pca/</link>
      <pubDate>Mon, 25 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/data_pca/</guid>
      <description>&lt;h2 id=&#34;quick-look&#34;&gt;Quick look&lt;/h2&gt;
&lt;p&gt;主成分分析（Principal component analysis, PCA）是一種強大且直觀的數據降維技術，被廣泛應用於臨床研究與醫學數據分析中。作為醫師，在日常工作中，我們經常面對大量的病患數據，例如基因表達數據、影像數據、實驗室檢驗值等。PCA能夠幫助我們提取數據的關鍵特徵，將高維度的資料轉換成易於解釋的低維度數據，從而揭示潛在的生物學意義。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;想要瞭接基本概念，可以看&lt;strong&gt;StatQuest&lt;/strong&gt;的&lt;a href=&#34;https://www.youtube.com/watch?v=FgakZw6K1QQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;影片&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;想快速了解數學概念的，可以看李政軒老師的&lt;a href=&#34;https://www.youtube.com/watch?v=JUPU8mJryL4&amp;amp;t=234s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;影片&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;主成分分析的數學基礎&#34;&gt;主成分分析的數學基礎&lt;/h1&gt;
&lt;h2 id=&#34;核心思想&#34;&gt;核心思想&lt;/h2&gt;
&lt;p&gt;PCA的目的是將高維數據投影到一組新的互相正交的坐標軸上（稱為主成分），這些軸的排列方式使得：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一個主成分最大程度地捕捉數據的變異性；&lt;/li&gt;
&lt;li&gt;第二個主成分捕捉剩餘變異性，且與第一主成分正交，依此類推。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;也就是在一堆雜亂的數據中，找到變異程度最大的主軸來最大程度的代表這群資料，接著PCA會逐步找到與這些主軸正交的其他軸，這些軸共同構成一組新的坐標系。而所有原始數據的值都會重新投影到新的軸上。每個空間中的數據點可以被所有主成分&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;&lt;strong&gt;線性加成&lt;/strong&gt;&lt;/span&gt;的方式來還原原始數據。整個過程可以大致簡化成如下的公式：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
S = C_{\text{mean}} + t_1C_1 + t_2C_2 + \dots \text{(t:主成分權重; C:主成分)}
$$
&lt;/div&gt;
&lt;h2 id=&#34;pca的目的&#34;&gt;PCA的目的&lt;/h2&gt;
&lt;p&gt;我自己在分析基因數據的時候也很常用到PCA，甚至有些R bioconductor package也將PCA當成是標準前處理過程，但其實一開始都會思考，目前有其他降維工具，為何PCA還是很多人用？關於PCA的目的，初略有以下三點：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;利用降維，去除高關聯性多餘的維度&lt;/li&gt;
&lt;li&gt;利用視覺化在2維的座標上，發現離群值或異常值&lt;/li&gt;
&lt;li&gt;跟隨最大離散程度的軸向，保留原始訊息&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由此可見，PCA可以幫助在目前動則維度數百的資料集中，還能用視覺化分析主要數據，並且評估哪些特徵維度不具有分群的效果，而可以考慮刪除或用其他方式過濾。&lt;/p&gt;
&lt;h2 id=&#34;數學過程&#34;&gt;數學過程&lt;/h2&gt;
&lt;p&gt;整個過程概念是先找到空間中數據點的平均值&lt;em&gt;x-mean&lt;/em&gt;，即數據的中心點，然後以&lt;em&gt;x-mean&lt;/em&gt;為原點，尋找通過此點的一個方向向量&lt;em&gt;e&lt;/em&gt;，對於所有數據點&lt;em&gt;xi&lt;/em&gt;，計算他們相對於&lt;em&gt;x-mean&lt;/em&gt;的差值，並將這些差值投影到方向&lt;em&gt;e&lt;/em&gt;上，在&lt;em&gt;e&lt;/em&gt;方向上的投影值的總變異性(即投影值平方的總和)如果達到最大值，則&lt;em&gt;e&lt;/em&gt;為第一主成分。
這邊的&lt;em&gt;e&lt;/em&gt;為長度為1的單位向量，也就是需要經過正規化(normalization)處理，此單位化向量確保了比較不同方向時，投影的變異性(方差)完全由數據本身決定，而非向量的長度。&lt;/p&gt;
&lt;p&gt;所有數據點投影後的長度可以表達為：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
\
e^T (\ x_1 - \bar{x}), e^T (\ x_2 - \bar{x}), \dots, e^T (\ x_n - \bar{x})
\
$$
&lt;/div&gt;
&lt;p&gt;而在&lt;em&gt;e&lt;/em&gt;上的數據變異度為：&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
\
\sigma^2 = \frac{1}{n} \sum_{i=1}^n \left( e^T (\ x_i - \bar{x}) - 0 \right)^2
\
$$
&lt;/div&gt;
&lt;p&gt;接下來把上面的公式拆開：
平方公式可以看成兩個相同的元素相乘。&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
\sigma^2 = \frac{1}{n} \sum_{i=1}^{n} \left(e^T (x_i - \bar{x}) \right)^2 = \frac{1}{n} \sum_{i=1}^{n} \left(e^T (x_i - \bar{x}) \right) \left(e^T (x_i - \bar{x}) \right)^T
$$
&lt;/div&gt;
&lt;p&gt;然而拆開為兩個矩陣，若要達到可以相乘的目的，後面的矩陣我們需要將其轉置。這邊我們回憶一下:
$$
(AB)^T=B^TA^T
$$
所以上面的公式可以變換成:&lt;/p&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
\frac{1}{n} \sum_{i=1}^n \left(e^T (x_i - \bar{x})\right) \left((x_i - \bar{x})^T e\right)
$$
&lt;/div&gt;
&lt;div style=&#34;overflow-x: scroll;&#34;&gt;
$$
=e^T \left( \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})(x_i - \bar{x})^T \right) e = e^T \Sigma e
$$
&lt;/div&gt;
到這邊我們已經可以發現，中間大框框包圍著的部分其實就是&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;共變異矩陣(covariance matrix)！&lt;/span&gt; 到此，我們已經可以看出來PCA要解的其實就是共變異矩陣。
&lt;p&gt;接下來我們要找到離散程度最大值出現的方向&lt;em&gt;e1&lt;/em&gt;:
$$
e_1 = \arg\max_{e} e^T \Sigma e, \quad e^T e = 1
$$&lt;/p&gt;
&lt;p&gt;這個算式若要求解，需要利用Lagrange function來針對約束條件來優化:
$$
f(e, \lambda) = e^T \Sigma e + \lambda (1 - e^T e)
$$
分別對參數進行偏微分後，得到：
$$
\frac{\partial f}{\partial e} = 2\Sigma e - 2\lambda e = 0 \implies \Sigma e = \lambda e
$$
及
$$
\frac{\partial f}{\partial \lambda} = 1 - e^T e = 0 \implies e^T e = 1
$$&lt;/p&gt;
&lt;p&gt;到此，線代魔王&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;eigenvalue&lt;/span&gt;現身了，搞了那麼久，PCA原來是要我們解eigenvalue problem!!
而不要忘記了，針對對稱矩陣，eigenvalue都有實數解，所以這邊必定能找到eigenvector，也就是eigenvalue對應的方向向量。
接下來我們只要做簡單的移項，就不難發現，我們要求解最大離散程度的&lt;em&gt;e1&lt;/em&gt;，就是eigenvalue最大值的地方!
$$
\lambda = e^T \Sigma e
$$
而第二主軸也可以依據Lagrange function來求解，但解完偏微分之後會發現，不管是接下來的哪個次主軸，解的都是跟原來的公式一模一樣，所以我們只要求第二大的eigenvalue以及其對應的相向即可!&lt;/p&gt;
&lt;h2 id=&#34;實際運用&#34;&gt;實際運用&lt;/h2&gt;
&lt;p&gt;古人云：千言萬語不如一行code，我們來直接用R來玩玩看PCA是怎麼達成並且視覺化的。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;#加載數據&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;set.seed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;123&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;matrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rnorm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;100&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mean&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ncol&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;colnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Feature1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Feature2&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Feature3&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;c1&#34;&gt;#標準化數據，將數據移到中心&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;scaled_data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;scale&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;center&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scale&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;#計算共變異矩陣&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;cov_matrix&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cov&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;scaled_data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;c1&#34;&gt;#計算共變異矩陣的特徵值和特徵向量&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;n&#34;&gt;eigen_result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;eigen&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cov_matrix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;n&#34;&gt;eigenvalues&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;eigen_result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;出來的eigen vectors:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;[,1]&lt;/th&gt;
          &lt;th&gt;[,2]&lt;/th&gt;
          &lt;th&gt;[,3]&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;[1,]&lt;/td&gt;
          &lt;td&gt;0.6733474&lt;/td&gt;
          &lt;td&gt;-0.1690336&lt;/td&gt;
          &lt;td&gt;0.7197436&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;[2,]&lt;/td&gt;
          &lt;td&gt;-0.3533758&lt;/td&gt;
          &lt;td&gt;-0.9286934&lt;/td&gt;
          &lt;td&gt;0.1124905&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;[3,]&lt;/td&gt;
          &lt;td&gt;-0.6494065&lt;/td&gt;
          &lt;td&gt;0.3300852&lt;/td&gt;
          &lt;td&gt;0.6850657&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;而eigenvalues:
[1] 1.1505778   [2] 0.9801158   [3] 0.8693063&lt;/p&gt;
&lt;p&gt;此時我們試著使用R中的&lt;strong&gt;prcomp&lt;/strong&gt;來直接操作PCA:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;#使用prcomp進行 PCA&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pca_result&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;prcomp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;center&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scale.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接著來同樣取出eigenvalues，看看是不是跟上面的一樣&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;#取出eigenvalues&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;prcomp_eigenvalues&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pca_result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sdev^2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;prcomp_eigenvalues&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;出來的eigenvalues:
[1] 1.1505778   [2] 0.9801158   [3] 0.8693063
跟上面操作的方式結果一至！&lt;/p&gt;
&lt;h2 id=&#34;pca的視覺化&#34;&gt;PCA的視覺化&lt;/h2&gt;
&lt;p&gt;接者我可以簡單的用&lt;strong&gt;ggfortify&lt;/strong&gt;套件來查看PCA的結果。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ggfortify&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;autoplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pca_result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;as.data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;colour&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;Feature1&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;ggtitle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;PCA Projection&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;theme_minimal&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;















&lt;figure  id=&#34;figure-pca-visualization&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pca&#34; srcset=&#34;
               /post/data_pca/fig1_hu15942855386301452877.webp 400w,
               /post/data_pca/fig1_hu4818452470569895218.webp 760w,
               /post/data_pca/fig1_hu7070961658534383816.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/data_pca/fig1_hu15942855386301452877.webp&#34;
               width=&#34;760&#34;
               height=&#34;656&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      PCA visualization
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;因為這個數據是隨機的，如果使用癌症基因數據，搭配一些顯著的臨床因子，視覺化後的分群應該會更漂亮。&lt;/p&gt;
&lt;h1 id=&#34;結論&#34;&gt;結論&lt;/h1&gt;
&lt;p&gt;主成分分析是一項將複雜數據轉化為清晰結構的強大工具，就像一個數據的解碼器，幫助我們從看似混亂的數據中提煉出最重要的線索。透過數學的魔力，我們不僅能找到數據中最大變異的方向，還能有效地降維並視覺化，讓原本高維的「迷霧森林」變成清晰的「航路圖」。&lt;/p&gt;
&lt;p&gt;在實際應用中，PCA不僅僅是一個數學公式，更是一種數據理解的思維方式。無論是在基因表達分析、醫學影像數據，還是多維臨床檢驗指標的綜合解讀中，PCA都能扮演一個「數據導航員」的角色，引領我們找到關鍵特徵，解決臨床問題，甚至發現潛在的生物學機制。&lt;/p&gt;
&lt;p&gt;當然PCA也有其缺點:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;解釋性不足: PCA的主成分是數學上計算出的線性組合，雖然能有效地捕捉數據的變異性，但每個主成分的實際意義通常不直觀，難以直接對應到具體的物理或生物學意義。例如，在醫學數據中，第一主成分可能代表數個臨床指標的綜合作用，但無法具體指出是哪一個指標在起主導作用。&lt;/li&gt;
&lt;li&gt;假設數據線性: PCA基於線性代數方法，假設數據之間的關係是線性的。然而，在很多實際問題中（如基因調控網絡、非線性動力學模型等），數據之間的關係可能是高度非線性的，這會導致PCA無法有效捕捉數據的真實結構。&lt;/li&gt;
&lt;li&gt;對數據尺度敏感: 如果數據的尺度(scale)差異很大，PCA的結果會嚴重受到影響。例如，一個變數的數值範圍是0-1，而另一個變數範圍是1-1000，後者會在主成分計算中占據主導地位。因此，PCA通常需要在降維前對數據進行標準化（Standardization），否則結果可能不準確。&lt;/li&gt;
&lt;li&gt;對離群值敏感: PCA對於數據中的離群值(outliers)非常敏感，這是因為離群值會極大地影響共變異矩陣的計算，進而改變主成分的方向。如果數據中存在明顯的離群值，PCA的結果可能會失真，導致降維效果變差。&lt;/li&gt;
&lt;li&gt;無法處理稀疏性問題: 在處理高維度但稀疏的數據（如基因表達數據或文本數據）時，PCA可能不是最佳選擇。這是因為PCA的降維過程會壓縮所有特徵的信息，導致稀疏結構丟失，無法保留某些特徵的稀疏性。&lt;/li&gt;
&lt;li&gt;依賴均值與共變異: PCA基於數據的均值和共變異矩陣，假設數據的主要信息可以用這些統計量來描述。如果數據的分佈偏離高斯分佈或共變異矩陣無法很好地捕捉數據結構，PCA的效果可能會受到限制。&lt;/li&gt;
&lt;li&gt;僅考慮變異性，無法考慮分類信息: PCA僅最大化數據的變異性，並不考慮下游任務(如分類或聚類)的需求。因此，如果主要目的是分類或分群，PCA降維後的特徵可能無法有效提高模型的性能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在實際使用時，需要結合數據特性、應用場景以及模型需求，選擇適合的降維方法，必要時可考慮其他技術（如t-SNE、UMAP或LDA）作為替代或輔助方法。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>黑色素瘤如何對免疫治療產生抗藥性？</title>
      <link>http://localhost:1313/post/paperr1/</link>
      <pubDate>Sat, 23 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/paperr1/</guid>
      <description>&lt;h2 id=&#34;quick-look&#34;&gt;Quick look&lt;/h2&gt;
&lt;p&gt;這篇&lt;a href=&#34;https://www.nature.com/articles/s41467-023-36979-y&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;文章&lt;/a&gt;研究了Immune checkpoint inhibitor（ICI）療法在黑色素瘤中(melanoma)的抗藥性機制。通過分析來自患者的短期腫瘤細胞系(short term cell line))和匹配的腫瘤樣本，作者發現了三種不同的抗藥性機制，分別涉及抗原表達的喪失、抗原呈現的破壞，以及與PTEN缺失相關的免疫細胞排斥。這些抗藥性機制揭示了可能的救援性治療策略，例如恢復MHC的表達、促進先天免疫反應、以及重新刺激抗原的呈現。&lt;/p&gt;
&lt;h1 id=&#34;簡介&#34;&gt;簡介&lt;/h1&gt;
&lt;p&gt;免疫檢查點抑制劑（ICI）針對PD-1的療法已徹底改變了轉移性黑色素瘤患者的治療方式。在許多III期臨床試驗中（如CheckMate-067和KEYNOTE-006），PD-1抑制劑顯示了42-45%的客觀反應率，以及6.5年42%的總體存活率。然而，約有55%的黑色素瘤患者對單獨的PD-1抑制劑療法存在先天性抗藥性，並且幾乎25%的患者在治療初期有反應，但在兩年內產生了抗藥性。因此，抗藥性問題仍然是ICI療法的一個重大挑戰。本研究通過全面分析黑色素瘤中對ICI的抗藥性機制，試圖探索這些ICI治療失敗的因素。&lt;/p&gt;
&lt;p&gt;為此，研究人員針對18名接受PD-1 抑制劑並且病程仍然持續進展的第四期黑色素瘤患者(9名PD-1抑制劑;9名PD-1抑制劑+CTLA4 抑制劑)進行切片，建立了22株短期腫瘤細胞系和匹配的腫瘤樣本，通過基因組、轉錄組和流式細胞儀的分析方法，探討抗藥性的產生機制。他們總結出了三個主要的抗藥性機制：抗原表達的喪失、抗原呈現的破壞和免疫細胞排斥，這些機制或許可能為治療提供新的想法。&lt;/p&gt;
&lt;h1 id=&#34;研究結果&#34;&gt;研究結果&lt;/h1&gt;
&lt;h2 id=&#34;抗原表達消失了&#34;&gt;抗原表達消失了？&lt;/h2&gt;
&lt;p&gt;因為約有4-10%對PD-1抑制劑有抗藥性的黑色素瘤具有&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;IFNγ(干擾素γ&lt;/span&gt;)功能的喪失，因此研究團隊以IFNγ的刺激來當切入點，結果發現，在22株細胞係接受IFNγ(1000 U/ml IFNγ，24小時)後，只有一株細胞(SCC16-0016)沒有反應，究其原因發現此細胞株之JAK2及INSL6基因有出現缺失或是融合的現象，AK2的缺失影響到MHC-I和MHC-II分子的表達，這是因為JAK2在IFNγ信號中負責&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;STAT1(信號轉導和轉錄活化因子1)&lt;/span&gt;的磷酸化，進而促使MHC的表達。JAK2缺失導致了STAT1無法被磷酸化，而這樣的缺陷導致這株細胞在接受IFNγ後無法正常表現MHC-I、MHC-II、PD-L1、PD-L2，也沒有出現細胞增殖趨緩的特徵，表示這條路徑影響到了此細胞株該有的免疫反應。而在短暫植入wild-type JAK2後，SCC16-0016得以順利在IFNγ刺激後表達MHC-I。&lt;/p&gt;
&lt;p&gt;而在剩下的21株細胞中，有6株細胞具有內源性IFNγ表現，而這種內源性的IFNγ是也被發現與黑色素瘤去分化(de-differentiated)有關(MITF與SOX10表現下降以及melanoma-specific antigen， Melan-A的喪失)(圖 1)。這種去分化的過程使腫瘤細胞喪失了wild-type抗原的表達能力，從而減少了腫瘤細胞的免疫原性(immunogenicty)，也削弱了腫瘤對免疫系統的可見性(visibility)。
















&lt;figure  id=&#34;figure-圖一&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Fig1&#34; srcset=&#34;
               /post/paperr1/fig1_hu9654123225570833926.webp 400w,
               /post/paperr1/fig1_hu9312653373427227540.webp 760w,
               /post/paperr1/fig1_hu15333842250656839342.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/paperr1/fig1_hu9654123225570833926.webp&#34;
               width=&#34;760&#34;
               height=&#34;407&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖一
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;內源性ifnγ造就免疫抑制的腫瘤微環境&#34;&gt;內源性IFNγ造就免疫抑制的腫瘤微環境？&lt;/h2&gt;
&lt;p&gt;雖然具有內源性IFNγ的細胞株也會表達較高與其調控相關的基因如IRF1/9、LGALS9與MHC-I，然而在細胞激素(cytokine/chemokine)分析時發現，這些細胞因為處於去分化的狀態，分泌的細胞激素與那些處於分化態的細胞在接受IFNγ刺激後不同，說明了不同細胞狀態在誘導免疫反應的複雜性。&lt;/p&gt;
&lt;p&gt;這些具有內源性IFNγ的細胞會對腫瘤微環境造成什麼影響呢？團隊接著利用多參數流式細胞分析發現，與此類細胞株配對之腫瘤具有較少的CD45+細胞含量與相對較高的巨噬細胞數量，同時也發現這類腫瘤有較少的活性CD8+ T細胞。&lt;/p&gt;
&lt;p&gt;另外針對SCC16-0016細胞株的配對腫瘤(JAK2 mutaant)分析後也發現，跟其他細胞株的配對腫瘤相比，SCC16-0016細胞株的配對腫瘤具有最高的NK細胞比例，這個發現也驗證了NK細胞會在第一防線時針對MHC-I陰性的癌細胞做攻擊的現象，也就是所謂的&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;missing self recognistion&lt;/span&gt;。&lt;/p&gt;
&lt;h2 id=&#34;抗原呈現遭到抑制&#34;&gt;抗原呈現遭到抑制？&lt;/h2&gt;
&lt;p&gt;因為這些去分化的腫瘤內表現抗原的程度較低，導致腫瘤內含有較少的活性CD8+ T細胞(透過分析表面標誌來確定如PD1++Tbet+)，為了證實這個現象並非只是同步發現的結果，團隊針對兩株去分化細胞株加載了HLA-A02載體後，以melan-A peptide來刺激，結果發現在共同培養的環境下，可以誘導CD8+ T細胞的活化(IFNγ+CD107+)(圖二)，表示植入的wild-type抗原有辦法增加免疫細胞的抗腫瘤能力。然而即便是植入抗原，仍然無法逆轉細胞型態成分化狀態。
















&lt;figure  id=&#34;figure-圖二&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig2&#34; srcset=&#34;
               /post/paperr1/fig2_hu14716284260067820646.webp 400w,
               /post/paperr1/fig2_hu3714876771964191745.webp 760w,
               /post/paperr1/fig2_hu13053414200563141755.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/paperr1/fig2_hu14716284260067820646.webp&#34;
               width=&#34;760&#34;
               height=&#34;629&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖二
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;複雜的機制讓抗原的表現消失&#34;&gt;複雜的機制，讓抗原的表現消失？&lt;/h2&gt;
&lt;p&gt;除了抗原表達的喪失外，研究還發現了一系列影響抗原呈現的獨立機制，這些機制也會導致免疫檢查點抑制劑的抗藥性。其中一個重要的機制是&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;B2M&lt;/span&gt;基因的功能喪失突變。團隊發現有兩株細胞具有B2M轉錄片段消失的現象，並且利用全轉錄組(whole transcriptome)及全外顯組(whole exome)分析確認了exon 1 deletion及frameshift mutation。B2M是MHC-I複合體的重要組成部分(&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S0304383521002937&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;圖三&lt;/a&gt;)，當B2M基因出現突變時，MHC-I的組裝和細胞表面表達均會受到影響，從而降低腫瘤細胞被T細胞識別的可能性。
















&lt;figure  id=&#34;figure-圖三&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;fig3&#34; srcset=&#34;
               /post/paperr1/fig3_hu15511228375094572697.webp 400w,
               /post/paperr1/fig3_hu17629593433813472757.webp 760w,
               /post/paperr1/fig3_hu17722807213131398297.webp 1200w&#34;
               src=&#34;http://localhost:1313/post/paperr1/fig3_hu15511228375094572697.webp&#34;
               width=&#34;760&#34;
               height=&#34;538&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      圖三
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;此外，&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;CIITA(MHC-II轉錄調控因子)&lt;/span&gt;基因的表達沉默也是一個關鍵因素。CIITA是控制MHC-II表達的核心轉錄因子，在具有B2M基因變異的細胞株中，若該基因被表觀遺傳機制（如DNA甲基化或組蛋白去乙醯化）抑制時，MHC-II的表達將顯著降低，進而影響抗原呈現。研究中通過表觀遺傳抑制劑（如HDAC抑制劑）恢復CIITA的表達，結果顯示MHC-II的表達可以部分恢復，這表明表觀遺傳調控在抗原呈遞中的重要性。這些結果告訴我們，造成黑色素瘤抗原消失的原因不只有IFNγ訊息路徑的問題，也有其他複雜的因素共同作用。&lt;/p&gt;
&lt;h2 id=&#34;免疫細胞排斥&#34;&gt;免疫細胞排斥？&lt;/h2&gt;
&lt;p&gt;&lt;span style=&#34;color: red; font-weight: bold&#34;&gt;PTEN&lt;/span&gt;基因的缺失與腫瘤中的免疫細胞排斥有著密切的關聯。PTEN是一個腫瘤抑制基因，其缺失會導致腫瘤細胞分泌更多的免疫抑制性分子，如TGF-β等，從而阻礙免疫細胞（尤其是CD8+ T細胞）進入腫瘤微環境。在研究中，PTEN缺失的黑色素瘤顯示出更低的CD8+ T細胞浸潤，並且在腫瘤微環境中存在更高比例的巨噬細胞，這些巨噬細胞通常具有免疫抑制的功能，進一步降低了腫瘤對免疫治療的反應。&lt;/p&gt;
&lt;p&gt;PTEN缺失的黑色素瘤還與腦轉移有關。研究發現，腦轉移腫瘤中PTEN缺失的比例較高，這些腫瘤不僅缺乏CD8+ T細胞的浸潤，還顯示出較高的調節性T細胞（Tregs）和suppressive myeloid細胞含量，這些免疫細胞的存在進一步加劇了腫瘤的免疫抑制狀態，使ICI療法難以奏效。&lt;/p&gt;
&lt;h1 id=&#34;探討&#34;&gt;探討&lt;/h1&gt;
&lt;p&gt;本研究結果顯示，黑色素瘤對免疫檢查點抑制劑的抗藥性主要涉及三大方面：抗原表達的喪失、抗原呈現的破壞以及免疫細胞排斥。抗原表達喪失與腫瘤細胞的去分化和內源性的IFNγ訊號有關，這些機制共同降低了腫瘤細胞的免疫抗原性，並使其難以被T細胞識別。抗原呈現的破壞則主要涉及MHC-I和MHC-II的異常，這些異常通常由基因突變或表觀遺傳調控引起。而PTEN的缺失則通過影響腫瘤微環境，抑制了免疫細胞的浸潤和活性，進一步促進了腫瘤的免疫逃脫。&lt;/p&gt;
&lt;p&gt;根據這些發現，研究者提出了一些潛在的治療救援策略。例如，對於抗原呈現異常的腫瘤，可以通過表觀遺傳調控劑（如HDAC抑制劑）恢復MHC表達，從而增強免疫系統對腫瘤的識別。此外，對於因PTEN缺失而造成免疫細胞排斥的腫瘤，可以考慮使用刺激先天免疫系統的療法，如Toll樣受體激動劑，來增強腫瘤微環境中的免疫活性。&lt;/p&gt;
&lt;p&gt;去分化的黑色素瘤則更具挑戰性，因為這些腫瘤通常表現出較高的抗藥性和免疫逃脫能力。研究者建議，結合免疫療法與促進鐵依賴性氧化壓力的藥物（如鐵死亡誘導劑），可能有助於改善免疫檢查點抑制劑的療效，因為先前研究發現去分化的黑色素瘤對鐵死亡誘導劑具有一定的敏感度。此外，針對腫瘤微環境中的免疫抑制因素，如Tregs和免疫抑制性巨噬細胞，也應該考慮相應的干預措施，以減少這些細胞對抗腫瘤免疫反應的負面影響。&lt;/p&gt;
&lt;p&gt;這項研究為理解黑色素瘤的免疫檢查點抑制劑抗藥性提供了重要的分子和功能線索，並為未來的治療策略提供了方向。通過精準識別不同的抗藥性機制，並針對性地進行治療，我們有望改善黑色素瘤患者的治療效果，特別是對於那些對現有免疫療法無反應的患者。這些新策略的探索與應用，將可能為免疫治療的救援治療開創新的局面。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>新文章發表於 European Urology</title>
      <link>http://localhost:1313/event/meta_publish/</link>
      <pubDate>Wed, 11 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/meta_publish/</guid>
      <description>&lt;h1 id=&#34;title&#34;&gt;Title&lt;/h1&gt;
&lt;p&gt;A Meta-Analysis and Meta-Regression of the Efficacy, Toxicity, and Quality of Life Outcomes Following Prostate-Specific Membrane Antigen Radioligand Therapy Utilising Lutetium-177 and Actinium- 225 in Metastatic Prostate Cancer&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;Background and objective: Management of metastatic prostate cancer (mPCa) presents significant challenges. In this systematic review, meta-analysis, and meta-regression, the efficacy, safety, and quality of life (QoL) outcomes of prostate-specific membrane antigen (PSMA)-targeted radioligand therapy (PRLT) utilising lutetium-177 ([177Lu]Lu-PSMA) and actinium-225 ([225Ac]Ac-PSMA) were assessed.&lt;/p&gt;
&lt;p&gt;Methods:
A detailed literature search across PubMed/Medline, EMBASE, Web of Science, Scopus, and Cochrane Library was conducted, culminating in the inclusion of 100 studies involving 8711 patients. Data on prostate-specific antigen (PSA) responses, toxicity profiles, and QoL and survival outcomes were analysed. Proportional meta-analyses and meta-regression analyses were performed.&lt;/p&gt;
&lt;p&gt;Key findings and limitations:
The estimated proportion of patients with PSA decline ≥50% was 0.49 for [177Lu]Lu-PSMA and 0.60 for [225Ac]Ac-PSMA in mPCa, particularly metastatic castration-resistant prostate cancer. A meta-regression analysis indicated an association between the cumulative amount of administered activity and the proportion of PSA ≥50% decline. Positive PSA responses were observed alongside improved overall survival across both therapies. Our analyses also identified the key factors associated with PSA responses and survival outcomes, including baseline haemoglobin level, and the presence of visceral metastases. Although anaemia was commonly observed, with [177Lu]Lu-PSMA, severe toxicities were infrequent. Improved QoL was observed following [177Lu]Lu-PSMA therapy, whereas it remained stable following the second cycle of [225Ac]Ac-PSMA treatment. Heterogeneity across studies for PSA responses and toxicity profiles is a limitation.&lt;/p&gt;
&lt;p&gt;Conclusions and clinical implications:
Our findings suggest an association between PRLT and reductions in PSA levels, as well as associations with enhanced survival outcomes in mPCa. Furthermore, our analysis shows a low incidence of severe toxicity associated with this treatment. These observations highlight the important role of PRLT in the management of mPCa.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>新 Preprint 發表於 biorxiv</title>
      <link>http://localhost:1313/event/driveromics/</link>
      <pubDate>Sun, 21 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/driveromics/</guid>
      <description>&lt;h1 id=&#34;title&#34;&gt;Title&lt;/h1&gt;
&lt;p&gt;DriverOmicsNet-An Integrated Graph Convolutional Network for Multi-Omics Exploration of Cancer Driver Genes&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;Background: Cancer is a complex and heterogeneous group of diseases driven by genetic mutations and molecular changes. Identifying and characterizing cancer driver genes (CDgs) is crucial for understanding cancer biology and guiding precision oncology. Integrating multi-omics data can reveal the intricate molecular interactions underlying cancer progression and treatment responses.&lt;/p&gt;
&lt;p&gt;Methods: We developed a graph convolutional network (GCN) framework, DriverOmicsNet, that integrates multi-omics data using STRING protein-protein interaction (PPI) networks and correlation-based weighted correlation network analysis (WGCNA). We applied this framework to 15 cancer types, analyzing 5555 tumor samples to predict cancer-related features such as homologous recombination deficiency (HRD), cancer stemness, immune clusters, tumor stage, and survival outcomes.&lt;/p&gt;
&lt;p&gt;Findings: DriverOmicsNet demonstrated superior predictive accuracy and model performance metrics across all target labels when compared with GCN models based on STRING network alone. Gene expression emerged as the most significant feature, reflecting the dynamic and functional state of cancer cells. The combined use of STRING PPI and WGCNA networks enhanced the identification of key driver genes and their interactions.&lt;/p&gt;
&lt;p&gt;Interpretation: Our study highlights the effectiveness of using GCNs to integrate multi-omics data for precision oncology. The integration of STRING PPI and WGCNA networks provides a comprehensive framework that improves predictive power and facilitates the understanding of cancer biology, paving the way for more tailored treatments.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>腎臟科國考複習</title>
      <link>http://localhost:1313/event/example/</link>
      <pubDate>Wed, 07 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/example/</guid>
      <description>

    
    &lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/bVHMlVoop68?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;
      &gt;&lt;/iframe&gt;
    &lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>新文章發表於Journal of Translational Medicine</title>
      <link>http://localhost:1313/event/lupus/</link>
      <pubDate>Fri, 03 Feb 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/event/lupus/</guid>
      <description>&lt;h1 id=&#34;title&#34;&gt;Title&lt;/h1&gt;
&lt;p&gt;Incorporating knowledge of disease-defining hub genes and regulatory network into a machine learning-based model for predicting treatment response in lupus nephritis after the first renal flare&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;Background:Identifying candidates responsive to treatment is important in lupus nephritis (LN) at the renal flare (RF) because an effective treatment can lower the risk of progression to end-stage kidney disease. However, machine learning (ML)-based models that address this issue are lacking.&lt;/p&gt;
&lt;p&gt;Methods:Transcriptomic profiles based on DNA microarray data were extracted from the GSE32591 and GSE112943 datasets. Comprehensive bioinformatics analyses were performed to identify disease-defining genes (DDGs). Peripheral blood samples (GSE81622, GSE99967, and GSE72326) were used to evaluate the effect of DDGs. Single-sample gene set enrichment analysis (ssGSEA) scores of the DDGs were calculated and correlated with specific immunology genes listed in the nCounter panel. GSE60681 and GSE69438 were used to examine the ability of the DDGs to discriminate LN from other renal diseases. K-means clustering was used to obtain the separate gene sets. The clustering results were extended to data derived using the nCounter technique. The least absolute shrinkage and selection operator (LASSO) algorithm was used to identify genes with high predictive value for treatment response after the first RF in each cluster. LASSO models with tenfold validation were built in GSE200306 and assessed by receiver operating characteristic (ROC) analysis with area under curve (AUC). The models were validated by using an independent dataset (GSE113342).&lt;/p&gt;
&lt;p&gt;Results:Forty-five hub genes specific to LN were identified. Eight optimal disease-defining clusters (DDCs) were identified in this study. Th1 and Th2 cell differentiation pathway was significantly enriched in DDC-6. LCK in DDC-6, whose expression positively correlated with various subsets of T cell infiltrations, was found to be differentially expressed between responders and non-responders and was ranked high in regulatory network analysis. Based on DDC-6, the prediction model had the best performance (AUC: 0.75; 95% confidence interval: 0.44–1 in the testing set) and high precision (0.83), recall (0.71), and F1 score (0.77) in the validation dataset.&lt;/p&gt;
&lt;p&gt;Conclusions:Our study demonstrates that incorporating knowledge of biological phenotypes into the ML model is feasible for evaluating treatment response after the first RF in LN. This knowledge-based incorporation improves the model&amp;rsquo;s transparency and performance. In addition, LCK may serve as a biomarker for T-cell infiltration and a therapeutic target in LN.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>http://localhost:1313/contact/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>People</title>
      <link>http://localhost:1313/people/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/people/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tour</title>
      <link>http://localhost:1313/tour/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/tour/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>http://localhost:1313/publication/preprint/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/preprint/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Add the publication&amp;rsquo;s &lt;strong&gt;full text&lt;/strong&gt; or &lt;strong&gt;supplementary notes&lt;/strong&gt; here. You can use rich formatting such as including &lt;a href=&#34;https://docs.hugoblox.com/content/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>http://localhost:1313/publication/journal-article/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Add the publication&amp;rsquo;s &lt;strong&gt;full text&lt;/strong&gt; or &lt;strong&gt;supplementary notes&lt;/strong&gt; here. You can use rich formatting such as including &lt;a href=&#34;https://docs.hugoblox.com/content/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>http://localhost:1313/publication/conference-paper/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Add the publication&amp;rsquo;s &lt;strong&gt;full text&lt;/strong&gt; or &lt;strong&gt;supplementary notes&lt;/strong&gt; here. You can use rich formatting such as including &lt;a href=&#34;https://docs.hugoblox.com/content/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/post/ucscxenatool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/ucscxenatool/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
